{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "박막 두께 측정_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFSUs0GeSZ3g96rgKUZRg+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/layer_thickness/blob/master/%EB%B0%95%EB%A7%89_%EB%91%90%EA%BB%98_%EC%B8%A1%EC%A0%95_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wHz4rdLwRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "373a3d39-9442-4e0a-fb63-d03ff72998fe"
      },
      "source": [
        "# 필요한 라이브러리 import\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 데이터 처리\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import * # 일단 싹 다. 모델평가를 해야해서...\n",
        "from sklearn.model_selection import * # 너도 싹 다.\n",
        "import tensorflow.keras\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "import tensorflow as tf\n",
        "\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uud-jSgvnX3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/4uiiurz1/keras-cosine-annealing/blob/master/cosine_annealing.py\n",
        "# pytorch와 달리 tensorflow의 keras에는 cosine anneling이 구현되어 있지 않아서 직접 구현해야함\n",
        "# open source활용\n",
        "import math\n",
        "from keras.callbacks import Callback\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class CosineAnnealingScheduler(Callback):\n",
        "    \"\"\"Cosine annealing scheduler.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n",
        "        super(CosineAnnealingScheduler, self).__init__()\n",
        "        self.T_max = T_max\n",
        "        self.eta_max = eta_max\n",
        "        self.eta_min = eta_min\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, 'lr'):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "        if self.verbose > 0:\n",
        "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
        "                  'rate to %s.' % (epoch + 1, lr))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCQbLmhzL0KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activation fucntion으로 gelu를 사용 gelu가 relu보다 효과가 좋음\n",
        "# Gaussian Error Linear Units\n",
        "class Gelu(Activation):\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Gelu, self).__init__(activation, **kwargs)\n",
        "        self.__name__='gelu'\n",
        "        \n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
        "\n",
        "get_custom_objects().update({'gelu': Gelu(gelu)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoYyfU7IL33o",
        "colab_type": "code",
        "outputId": "8215a679-363f-4681-b98b-cd21e8c60628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# 구글 드라이브 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY-_48EsMJra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/content/gdrive/My Drive/machine_learning/박막두께/train_set.csv', index_col = 0)\n",
        "test = pd.read_csv('/content/gdrive/My Drive/machine_learning/박막두께/test_set.csv', index_col = 0)\n",
        "sample_submission = pd.read_csv('/content/gdrive/My Drive/machine_learning/박막두께/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr6gX8a1MNh5",
        "colab_type": "code",
        "outputId": "4843f5fa-dd66-4a67-e53b-2e20255877aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "# 데이터 요약\n",
        "print(train.describe())\n",
        "print(test.describe())\n",
        "print(sample_submission.describe())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             layer_1        layer_2  ...            224            225\n",
            "count  170100.000000  170100.000000  ...  170100.000000  170100.000000\n",
            "mean      155.043269     155.010053  ...       0.631455       0.633718\n",
            "std        86.527234      86.602764  ...       0.195622       0.195101\n",
            "min        10.000000      10.000000  ...      -0.005321      -0.005659\n",
            "25%        80.000000      80.000000  ...       0.508407       0.511000\n",
            "50%       160.000000     160.000000  ...       0.677139       0.679399\n",
            "75%       230.000000     230.000000  ...       0.787409       0.789263\n",
            "max       300.000000     300.000000  ...       0.941404       0.943648\n",
            "\n",
            "[8 rows x 230 columns]\n",
            "                  0             1  ...           224           225\n",
            "count  18900.000000  18900.000000  ...  18900.000000  18900.000000\n",
            "mean       0.297972      0.298041  ...      0.632419      0.634869\n",
            "std        0.182991      0.183320  ...      0.194512      0.194490\n",
            "min       -0.013451     -0.013265  ...     -0.001584     -0.005085\n",
            "25%        0.138633      0.140467  ...      0.514230      0.517084\n",
            "50%        0.292453      0.292547  ...      0.677810      0.680802\n",
            "75%        0.443753      0.443661  ...      0.786448      0.788634\n",
            "max        0.739840      0.738960  ...      0.934890      0.939436\n",
            "\n",
            "[8 rows x 226 columns]\n",
            "                id  layer_1  layer_2  layer_3  layer_4\n",
            "count  18900.00000  18900.0  18900.0  18900.0  18900.0\n",
            "mean    9449.50000      0.0      0.0      0.0      0.0\n",
            "std     5456.10438      0.0      0.0      0.0      0.0\n",
            "min        0.00000      0.0      0.0      0.0      0.0\n",
            "25%     4724.75000      0.0      0.0      0.0      0.0\n",
            "50%     9449.50000      0.0      0.0      0.0      0.0\n",
            "75%    14174.25000      0.0      0.0      0.0      0.0\n",
            "max    18899.00000      0.0      0.0      0.0      0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLbeIZ6cMOfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 슬라이싱을 통한 변수분리\n",
        "## 자료형은 pandas가 아닌 numpy\n",
        "train_X = np.array(train.iloc[:, 4:]) \n",
        "train_Y = np.array(train.iloc[:,0:4])\n",
        "test_X = np.array(test.iloc[:, 0:]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKcs50kZMU2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델을 평가하기 위한 데이터분리 (비율은 10%)\n",
        "# random_state는 튜닝가능한 하이퍼 파라미터?\n",
        "\n",
        "x_train, x_eval, y_train, y_eval = train_test_split(train_X, train_Y, test_size = 0.1, random_state = 52)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzk0OVkUpozC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSoJQvzxMPxy",
        "colab_type": "code",
        "outputId": "241d6a2f-c009-4a1f-e951-ec6f7bd78519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "drop_ratio = 0.0001\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(2017, input_dim = len(x_train[0])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "\n",
        "model.add(Dense(2013))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "\n",
        "model.add(Dense(1027))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "\n",
        "model.add(Dense(517))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "\n",
        "model.add(Dense(509))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "\n",
        "model.add(Dense(503))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4))\n",
        "model.add(Activation(gelu))\n",
        "model.add(Dropout(drop_ratio))\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_47 (Dense)             (None, 2017)              457859    \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 2017)              8068      \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 2017)              0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 2017)              0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 2013)              4062234   \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 2013)              8052      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 2013)              0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 2013)              0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 1027)              2068378   \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 1027)              4108      \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 1027)              0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 1027)              0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 517)               531476    \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 517)               2068      \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 517)               0         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 517)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 509)               263662    \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 509)               2036      \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 509)               0         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 509)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 503)               256530    \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 503)               2012      \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 503)               0         \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 503)               0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 503)               0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 4)                 2016      \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 7,668,499\n",
            "Trainable params: 7,655,327\n",
            "Non-trainable params: 13,172\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkWLc4dniKIj",
        "colab_type": "code",
        "outputId": "02cd1771-0329-4087-c74a-204cb6200d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "lr = 3e-4\n",
        "lr_d = 0.0\n",
        "patience = 200\n",
        "\n",
        "n_fold = 13\n",
        "k_fold = KFold(n_splits = n_fold, shuffle = True, random_state = 1000).split(x_train, y_train)  \n",
        "\n",
        "for k, (train, test) in enumerate(k_fold):\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-36cc31807735>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSywf_rIMSjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mae', optimizer= 'nadam', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56FMbut8M8Wo",
        "colab_type": "code",
        "outputId": "2a6e4735-7f76-4fc3-e1c7-fb9b381d6da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size = 4096, epochs = 1000, validation_split = 0.05, verbose = 2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "36/36 - 5s - loss: 150.2932 - mae: 150.2932 - val_loss: 139.3398 - val_mae: 139.3398\n",
            "Epoch 2/1000\n",
            "36/36 - 4s - loss: 143.5486 - mae: 143.5486 - val_loss: 122.6136 - val_mae: 122.6136\n",
            "Epoch 3/1000\n",
            "36/36 - 4s - loss: 134.8091 - mae: 134.8091 - val_loss: 139.1183 - val_mae: 139.1183\n",
            "Epoch 4/1000\n",
            "36/36 - 4s - loss: 123.2373 - mae: 123.2373 - val_loss: 133.5892 - val_mae: 133.5892\n",
            "Epoch 5/1000\n",
            "36/36 - 4s - loss: 109.7919 - mae: 109.7919 - val_loss: 133.4434 - val_mae: 133.4434\n",
            "Epoch 6/1000\n",
            "36/36 - 4s - loss: 95.6329 - mae: 95.6329 - val_loss: 137.3997 - val_mae: 137.3997\n",
            "Epoch 7/1000\n",
            "36/36 - 4s - loss: 81.9551 - mae: 81.9551 - val_loss: 130.9613 - val_mae: 130.9613\n",
            "Epoch 8/1000\n",
            "36/36 - 4s - loss: 69.9660 - mae: 69.9660 - val_loss: 135.2955 - val_mae: 135.2955\n",
            "Epoch 9/1000\n",
            "36/36 - 4s - loss: 58.9407 - mae: 58.9407 - val_loss: 127.7803 - val_mae: 127.7803\n",
            "Epoch 10/1000\n",
            "36/36 - 4s - loss: 47.8516 - mae: 47.8516 - val_loss: 106.0811 - val_mae: 106.0811\n",
            "Epoch 11/1000\n",
            "36/36 - 4s - loss: 36.9469 - mae: 36.9469 - val_loss: 81.9188 - val_mae: 81.9188\n",
            "Epoch 12/1000\n",
            "36/36 - 4s - loss: 27.5277 - mae: 27.5277 - val_loss: 66.7339 - val_mae: 66.7339\n",
            "Epoch 13/1000\n",
            "36/36 - 4s - loss: 19.5512 - mae: 19.5512 - val_loss: 50.0896 - val_mae: 50.0896\n",
            "Epoch 14/1000\n",
            "36/36 - 4s - loss: 13.6331 - mae: 13.6331 - val_loss: 39.6343 - val_mae: 39.6343\n",
            "Epoch 15/1000\n",
            "36/36 - 4s - loss: 10.3647 - mae: 10.3647 - val_loss: 32.0506 - val_mae: 32.0506\n",
            "Epoch 16/1000\n",
            "36/36 - 4s - loss: 8.9481 - mae: 8.9481 - val_loss: 25.2527 - val_mae: 25.2527\n",
            "Epoch 17/1000\n",
            "36/36 - 4s - loss: 7.5970 - mae: 7.5970 - val_loss: 19.5329 - val_mae: 19.5329\n",
            "Epoch 18/1000\n",
            "36/36 - 4s - loss: 6.8695 - mae: 6.8695 - val_loss: 15.2336 - val_mae: 15.2336\n",
            "Epoch 19/1000\n",
            "36/36 - 4s - loss: 6.3681 - mae: 6.3681 - val_loss: 12.7026 - val_mae: 12.7026\n",
            "Epoch 20/1000\n",
            "36/36 - 4s - loss: 5.7968 - mae: 5.7968 - val_loss: 9.9708 - val_mae: 9.9708\n",
            "Epoch 21/1000\n",
            "36/36 - 4s - loss: 5.4402 - mae: 5.4402 - val_loss: 8.5671 - val_mae: 8.5671\n",
            "Epoch 22/1000\n",
            "36/36 - 4s - loss: 5.1830 - mae: 5.1830 - val_loss: 7.4270 - val_mae: 7.4270\n",
            "Epoch 23/1000\n",
            "36/36 - 4s - loss: 4.9068 - mae: 4.9068 - val_loss: 6.5835 - val_mae: 6.5835\n",
            "Epoch 24/1000\n",
            "36/36 - 4s - loss: 4.6932 - mae: 4.6932 - val_loss: 6.1290 - val_mae: 6.1290\n",
            "Epoch 25/1000\n",
            "36/36 - 4s - loss: 4.5720 - mae: 4.5720 - val_loss: 6.1673 - val_mae: 6.1673\n",
            "Epoch 26/1000\n",
            "36/36 - 4s - loss: 4.3729 - mae: 4.3729 - val_loss: 5.3422 - val_mae: 5.3422\n",
            "Epoch 27/1000\n",
            "36/36 - 4s - loss: 4.3644 - mae: 4.3644 - val_loss: 5.4932 - val_mae: 5.4932\n",
            "Epoch 28/1000\n",
            "36/36 - 4s - loss: 4.1466 - mae: 4.1466 - val_loss: 5.3333 - val_mae: 5.3333\n",
            "Epoch 29/1000\n",
            "36/36 - 4s - loss: 4.0549 - mae: 4.0549 - val_loss: 4.6549 - val_mae: 4.6549\n",
            "Epoch 30/1000\n",
            "36/36 - 4s - loss: 3.8915 - mae: 3.8915 - val_loss: 4.5566 - val_mae: 4.5566\n",
            "Epoch 31/1000\n",
            "36/36 - 4s - loss: 3.8174 - mae: 3.8174 - val_loss: 4.7397 - val_mae: 4.7397\n",
            "Epoch 32/1000\n",
            "36/36 - 4s - loss: 3.6404 - mae: 3.6404 - val_loss: 4.2040 - val_mae: 4.2040\n",
            "Epoch 33/1000\n",
            "36/36 - 4s - loss: 3.6270 - mae: 3.6270 - val_loss: 4.2191 - val_mae: 4.2191\n",
            "Epoch 34/1000\n",
            "36/36 - 4s - loss: 3.7334 - mae: 3.7334 - val_loss: 4.0713 - val_mae: 4.0713\n",
            "Epoch 35/1000\n",
            "36/36 - 4s - loss: 3.7233 - mae: 3.7233 - val_loss: 4.3089 - val_mae: 4.3089\n",
            "Epoch 36/1000\n",
            "36/36 - 4s - loss: 3.5389 - mae: 3.5389 - val_loss: 3.8660 - val_mae: 3.8660\n",
            "Epoch 37/1000\n",
            "36/36 - 4s - loss: 3.3977 - mae: 3.3977 - val_loss: 3.8297 - val_mae: 3.8297\n",
            "Epoch 38/1000\n",
            "36/36 - 4s - loss: 3.3587 - mae: 3.3587 - val_loss: 4.0252 - val_mae: 4.0252\n",
            "Epoch 39/1000\n",
            "36/36 - 4s - loss: 3.2961 - mae: 3.2961 - val_loss: 3.7451 - val_mae: 3.7451\n",
            "Epoch 40/1000\n",
            "36/36 - 4s - loss: 3.1788 - mae: 3.1788 - val_loss: 3.4968 - val_mae: 3.4968\n",
            "Epoch 41/1000\n",
            "36/36 - 4s - loss: 3.0911 - mae: 3.0911 - val_loss: 3.6740 - val_mae: 3.6740\n",
            "Epoch 42/1000\n",
            "36/36 - 4s - loss: 3.1641 - mae: 3.1641 - val_loss: 3.3699 - val_mae: 3.3699\n",
            "Epoch 43/1000\n",
            "36/36 - 4s - loss: 3.0690 - mae: 3.0690 - val_loss: 3.5740 - val_mae: 3.5740\n",
            "Epoch 44/1000\n",
            "36/36 - 4s - loss: 2.9238 - mae: 2.9238 - val_loss: 3.1392 - val_mae: 3.1392\n",
            "Epoch 45/1000\n",
            "36/36 - 4s - loss: 2.9439 - mae: 2.9439 - val_loss: 3.6005 - val_mae: 3.6005\n",
            "Epoch 46/1000\n",
            "36/36 - 4s - loss: 3.0623 - mae: 3.0623 - val_loss: 3.3211 - val_mae: 3.3211\n",
            "Epoch 47/1000\n",
            "36/36 - 4s - loss: 2.9025 - mae: 2.9025 - val_loss: 3.4050 - val_mae: 3.4050\n",
            "Epoch 48/1000\n",
            "36/36 - 4s - loss: 2.9583 - mae: 2.9583 - val_loss: 3.1900 - val_mae: 3.1900\n",
            "Epoch 49/1000\n",
            "36/36 - 4s - loss: 2.9873 - mae: 2.9873 - val_loss: 3.0948 - val_mae: 3.0948\n",
            "Epoch 50/1000\n",
            "36/36 - 4s - loss: 2.8289 - mae: 2.8289 - val_loss: 3.1280 - val_mae: 3.1280\n",
            "Epoch 51/1000\n",
            "36/36 - 4s - loss: 2.7930 - mae: 2.7930 - val_loss: 3.0259 - val_mae: 3.0259\n",
            "Epoch 52/1000\n",
            "36/36 - 4s - loss: 2.8220 - mae: 2.8220 - val_loss: 3.2403 - val_mae: 3.2403\n",
            "Epoch 53/1000\n",
            "36/36 - 4s - loss: 2.7048 - mae: 2.7048 - val_loss: 2.9841 - val_mae: 2.9841\n",
            "Epoch 54/1000\n",
            "36/36 - 4s - loss: 2.8164 - mae: 2.8164 - val_loss: 3.0322 - val_mae: 3.0322\n",
            "Epoch 55/1000\n",
            "36/36 - 4s - loss: 2.8475 - mae: 2.8475 - val_loss: 3.2348 - val_mae: 3.2348\n",
            "Epoch 56/1000\n",
            "36/36 - 4s - loss: 2.8639 - mae: 2.8639 - val_loss: 2.9479 - val_mae: 2.9479\n",
            "Epoch 57/1000\n",
            "36/36 - 4s - loss: 2.7407 - mae: 2.7407 - val_loss: 2.8387 - val_mae: 2.8387\n",
            "Epoch 58/1000\n",
            "36/36 - 4s - loss: 2.7080 - mae: 2.7080 - val_loss: 2.8190 - val_mae: 2.8190\n",
            "Epoch 59/1000\n",
            "36/36 - 4s - loss: 2.6249 - mae: 2.6249 - val_loss: 2.7136 - val_mae: 2.7136\n",
            "Epoch 60/1000\n",
            "36/36 - 4s - loss: 2.6438 - mae: 2.6438 - val_loss: 2.8821 - val_mae: 2.8821\n",
            "Epoch 61/1000\n",
            "36/36 - 4s - loss: 2.5982 - mae: 2.5982 - val_loss: 2.9769 - val_mae: 2.9769\n",
            "Epoch 62/1000\n",
            "36/36 - 4s - loss: 2.5684 - mae: 2.5684 - val_loss: 2.6956 - val_mae: 2.6956\n",
            "Epoch 63/1000\n",
            "36/36 - 4s - loss: 2.6515 - mae: 2.6515 - val_loss: 2.8979 - val_mae: 2.8979\n",
            "Epoch 64/1000\n",
            "36/36 - 4s - loss: 2.6078 - mae: 2.6078 - val_loss: 2.6750 - val_mae: 2.6750\n",
            "Epoch 65/1000\n",
            "36/36 - 4s - loss: 2.5416 - mae: 2.5416 - val_loss: 2.6537 - val_mae: 2.6537\n",
            "Epoch 66/1000\n",
            "36/36 - 4s - loss: 2.4818 - mae: 2.4818 - val_loss: 2.6346 - val_mae: 2.6346\n",
            "Epoch 67/1000\n",
            "36/36 - 4s - loss: 2.4066 - mae: 2.4066 - val_loss: 2.4896 - val_mae: 2.4896\n",
            "Epoch 68/1000\n",
            "36/36 - 4s - loss: 2.4873 - mae: 2.4873 - val_loss: 2.9008 - val_mae: 2.9008\n",
            "Epoch 69/1000\n",
            "36/36 - 4s - loss: 2.5362 - mae: 2.5362 - val_loss: 2.7556 - val_mae: 2.7556\n",
            "Epoch 70/1000\n",
            "36/36 - 4s - loss: 2.5818 - mae: 2.5818 - val_loss: 2.7195 - val_mae: 2.7195\n",
            "Epoch 71/1000\n",
            "36/36 - 4s - loss: 2.4290 - mae: 2.4290 - val_loss: 2.4667 - val_mae: 2.4667\n",
            "Epoch 72/1000\n",
            "36/36 - 4s - loss: 2.5580 - mae: 2.5580 - val_loss: 2.8933 - val_mae: 2.8933\n",
            "Epoch 73/1000\n",
            "36/36 - 4s - loss: 2.4106 - mae: 2.4106 - val_loss: 2.5851 - val_mae: 2.5851\n",
            "Epoch 74/1000\n",
            "36/36 - 4s - loss: 2.3111 - mae: 2.3111 - val_loss: 2.3109 - val_mae: 2.3109\n",
            "Epoch 75/1000\n",
            "36/36 - 4s - loss: 2.4408 - mae: 2.4408 - val_loss: 2.4550 - val_mae: 2.4550\n",
            "Epoch 76/1000\n",
            "36/36 - 4s - loss: 2.3799 - mae: 2.3799 - val_loss: 2.5445 - val_mae: 2.5445\n",
            "Epoch 77/1000\n",
            "36/36 - 4s - loss: 2.3886 - mae: 2.3886 - val_loss: 2.7153 - val_mae: 2.7153\n",
            "Epoch 78/1000\n",
            "36/36 - 4s - loss: 2.4128 - mae: 2.4128 - val_loss: 2.3287 - val_mae: 2.3287\n",
            "Epoch 79/1000\n",
            "36/36 - 4s - loss: 2.3117 - mae: 2.3117 - val_loss: 2.2827 - val_mae: 2.2827\n",
            "Epoch 80/1000\n",
            "36/36 - 4s - loss: 2.2954 - mae: 2.2954 - val_loss: 2.4923 - val_mae: 2.4923\n",
            "Epoch 81/1000\n",
            "36/36 - 4s - loss: 2.3788 - mae: 2.3788 - val_loss: 2.5661 - val_mae: 2.5661\n",
            "Epoch 82/1000\n",
            "36/36 - 4s - loss: 2.2672 - mae: 2.2672 - val_loss: 2.3000 - val_mae: 2.3000\n",
            "Epoch 83/1000\n",
            "36/36 - 4s - loss: 2.2054 - mae: 2.2054 - val_loss: 2.3881 - val_mae: 2.3881\n",
            "Epoch 84/1000\n",
            "36/36 - 4s - loss: 2.3394 - mae: 2.3394 - val_loss: 2.3895 - val_mae: 2.3895\n",
            "Epoch 85/1000\n",
            "36/36 - 4s - loss: 2.2476 - mae: 2.2476 - val_loss: 2.2691 - val_mae: 2.2691\n",
            "Epoch 86/1000\n",
            "36/36 - 4s - loss: 2.2737 - mae: 2.2737 - val_loss: 2.1859 - val_mae: 2.1859\n",
            "Epoch 87/1000\n",
            "36/36 - 4s - loss: 2.2336 - mae: 2.2336 - val_loss: 2.1293 - val_mae: 2.1293\n",
            "Epoch 88/1000\n",
            "36/36 - 4s - loss: 2.1785 - mae: 2.1785 - val_loss: 2.2282 - val_mae: 2.2282\n",
            "Epoch 89/1000\n",
            "36/36 - 4s - loss: 2.2223 - mae: 2.2223 - val_loss: 2.1795 - val_mae: 2.1795\n",
            "Epoch 90/1000\n",
            "36/36 - 4s - loss: 2.1883 - mae: 2.1883 - val_loss: 2.2646 - val_mae: 2.2646\n",
            "Epoch 91/1000\n",
            "36/36 - 4s - loss: 2.1140 - mae: 2.1140 - val_loss: 2.2936 - val_mae: 2.2936\n",
            "Epoch 92/1000\n",
            "36/36 - 4s - loss: 2.2622 - mae: 2.2622 - val_loss: 2.2804 - val_mae: 2.2804\n",
            "Epoch 93/1000\n",
            "36/36 - 4s - loss: 2.2895 - mae: 2.2895 - val_loss: 2.3464 - val_mae: 2.3464\n",
            "Epoch 94/1000\n",
            "36/36 - 4s - loss: 2.2228 - mae: 2.2228 - val_loss: 2.4482 - val_mae: 2.4482\n",
            "Epoch 95/1000\n",
            "36/36 - 4s - loss: 2.2831 - mae: 2.2831 - val_loss: 2.2993 - val_mae: 2.2993\n",
            "Epoch 96/1000\n",
            "36/36 - 4s - loss: 2.1987 - mae: 2.1987 - val_loss: 2.2386 - val_mae: 2.2386\n",
            "Epoch 97/1000\n",
            "36/36 - 4s - loss: 2.0756 - mae: 2.0756 - val_loss: 2.2123 - val_mae: 2.2123\n",
            "Epoch 98/1000\n",
            "36/36 - 4s - loss: 2.2281 - mae: 2.2281 - val_loss: 2.2042 - val_mae: 2.2042\n",
            "Epoch 99/1000\n",
            "36/36 - 4s - loss: 2.1732 - mae: 2.1732 - val_loss: 2.2349 - val_mae: 2.2349\n",
            "Epoch 100/1000\n",
            "36/36 - 4s - loss: 2.0919 - mae: 2.0919 - val_loss: 2.1698 - val_mae: 2.1698\n",
            "Epoch 101/1000\n",
            "36/36 - 4s - loss: 2.2483 - mae: 2.2483 - val_loss: 2.1549 - val_mae: 2.1549\n",
            "Epoch 102/1000\n",
            "36/36 - 4s - loss: 2.1475 - mae: 2.1475 - val_loss: 2.2490 - val_mae: 2.2490\n",
            "Epoch 103/1000\n",
            "36/36 - 4s - loss: 2.0848 - mae: 2.0848 - val_loss: 2.3070 - val_mae: 2.3070\n",
            "Epoch 104/1000\n",
            "36/36 - 4s - loss: 2.1579 - mae: 2.1579 - val_loss: 2.1742 - val_mae: 2.1742\n",
            "Epoch 105/1000\n",
            "36/36 - 4s - loss: 2.1826 - mae: 2.1826 - val_loss: 2.1198 - val_mae: 2.1198\n",
            "Epoch 106/1000\n",
            "36/36 - 4s - loss: 2.1358 - mae: 2.1358 - val_loss: 2.2242 - val_mae: 2.2242\n",
            "Epoch 107/1000\n",
            "36/36 - 4s - loss: 2.1296 - mae: 2.1296 - val_loss: 2.3384 - val_mae: 2.3384\n",
            "Epoch 108/1000\n",
            "36/36 - 4s - loss: 2.0792 - mae: 2.0792 - val_loss: 2.1844 - val_mae: 2.1844\n",
            "Epoch 109/1000\n",
            "36/36 - 4s - loss: 2.0286 - mae: 2.0286 - val_loss: 2.2046 - val_mae: 2.2046\n",
            "Epoch 110/1000\n",
            "36/36 - 4s - loss: 2.0291 - mae: 2.0291 - val_loss: 2.0480 - val_mae: 2.0480\n",
            "Epoch 111/1000\n",
            "36/36 - 4s - loss: 2.0787 - mae: 2.0787 - val_loss: 2.2488 - val_mae: 2.2488\n",
            "Epoch 112/1000\n",
            "36/36 - 4s - loss: 2.0134 - mae: 2.0134 - val_loss: 2.1357 - val_mae: 2.1357\n",
            "Epoch 113/1000\n",
            "36/36 - 4s - loss: 2.1116 - mae: 2.1116 - val_loss: 1.9737 - val_mae: 1.9737\n",
            "Epoch 114/1000\n",
            "36/36 - 4s - loss: 1.9916 - mae: 1.9916 - val_loss: 2.0969 - val_mae: 2.0969\n",
            "Epoch 115/1000\n",
            "36/36 - 4s - loss: 2.0429 - mae: 2.0429 - val_loss: 2.0270 - val_mae: 2.0270\n",
            "Epoch 116/1000\n",
            "36/36 - 4s - loss: 2.0464 - mae: 2.0464 - val_loss: 2.0129 - val_mae: 2.0129\n",
            "Epoch 117/1000\n",
            "36/36 - 4s - loss: 2.0058 - mae: 2.0058 - val_loss: 2.0904 - val_mae: 2.0904\n",
            "Epoch 118/1000\n",
            "36/36 - 4s - loss: 1.9907 - mae: 1.9907 - val_loss: 2.2564 - val_mae: 2.2564\n",
            "Epoch 119/1000\n",
            "36/36 - 4s - loss: 2.0471 - mae: 2.0471 - val_loss: 1.9911 - val_mae: 1.9911\n",
            "Epoch 120/1000\n",
            "36/36 - 4s - loss: 2.1283 - mae: 2.1283 - val_loss: 2.0321 - val_mae: 2.0321\n",
            "Epoch 121/1000\n",
            "36/36 - 4s - loss: 2.0788 - mae: 2.0788 - val_loss: 2.0209 - val_mae: 2.0209\n",
            "Epoch 122/1000\n",
            "36/36 - 4s - loss: 1.9635 - mae: 1.9635 - val_loss: 1.9130 - val_mae: 1.9130\n",
            "Epoch 123/1000\n",
            "36/36 - 4s - loss: 1.9765 - mae: 1.9765 - val_loss: 2.0941 - val_mae: 2.0941\n",
            "Epoch 124/1000\n",
            "36/36 - 4s - loss: 2.0254 - mae: 2.0254 - val_loss: 2.2104 - val_mae: 2.2104\n",
            "Epoch 125/1000\n",
            "36/36 - 4s - loss: 2.0010 - mae: 2.0010 - val_loss: 2.3562 - val_mae: 2.3562\n",
            "Epoch 126/1000\n",
            "36/36 - 4s - loss: 2.0327 - mae: 2.0327 - val_loss: 1.8588 - val_mae: 1.8588\n",
            "Epoch 127/1000\n",
            "36/36 - 4s - loss: 2.0141 - mae: 2.0141 - val_loss: 2.0928 - val_mae: 2.0928\n",
            "Epoch 128/1000\n",
            "36/36 - 4s - loss: 1.9387 - mae: 1.9387 - val_loss: 1.9371 - val_mae: 1.9371\n",
            "Epoch 129/1000\n",
            "36/36 - 4s - loss: 2.0079 - mae: 2.0079 - val_loss: 2.1837 - val_mae: 2.1837\n",
            "Epoch 130/1000\n",
            "36/36 - 4s - loss: 1.9606 - mae: 1.9606 - val_loss: 2.0098 - val_mae: 2.0098\n",
            "Epoch 131/1000\n",
            "36/36 - 4s - loss: 1.9398 - mae: 1.9398 - val_loss: 1.8399 - val_mae: 1.8399\n",
            "Epoch 132/1000\n",
            "36/36 - 4s - loss: 1.9212 - mae: 1.9212 - val_loss: 1.9271 - val_mae: 1.9271\n",
            "Epoch 133/1000\n",
            "36/36 - 4s - loss: 1.9589 - mae: 1.9589 - val_loss: 1.8854 - val_mae: 1.8854\n",
            "Epoch 134/1000\n",
            "36/36 - 4s - loss: 1.9488 - mae: 1.9488 - val_loss: 2.2637 - val_mae: 2.2637\n",
            "Epoch 135/1000\n",
            "36/36 - 4s - loss: 1.9842 - mae: 1.9842 - val_loss: 2.1489 - val_mae: 2.1489\n",
            "Epoch 136/1000\n",
            "36/36 - 4s - loss: 1.9888 - mae: 1.9888 - val_loss: 1.9154 - val_mae: 1.9154\n",
            "Epoch 137/1000\n",
            "36/36 - 4s - loss: 1.9532 - mae: 1.9532 - val_loss: 2.0786 - val_mae: 2.0786\n",
            "Epoch 138/1000\n",
            "36/36 - 4s - loss: 1.8256 - mae: 1.8256 - val_loss: 1.9220 - val_mae: 1.9220\n",
            "Epoch 139/1000\n",
            "36/36 - 4s - loss: 1.8715 - mae: 1.8715 - val_loss: 1.8246 - val_mae: 1.8246\n",
            "Epoch 140/1000\n",
            "36/36 - 4s - loss: 1.8651 - mae: 1.8651 - val_loss: 1.8146 - val_mae: 1.8146\n",
            "Epoch 141/1000\n",
            "36/36 - 4s - loss: 2.0205 - mae: 2.0205 - val_loss: 1.7779 - val_mae: 1.7779\n",
            "Epoch 142/1000\n",
            "36/36 - 4s - loss: 1.9716 - mae: 1.9716 - val_loss: 2.0326 - val_mae: 2.0326\n",
            "Epoch 143/1000\n",
            "36/36 - 4s - loss: 1.9133 - mae: 1.9133 - val_loss: 1.8967 - val_mae: 1.8967\n",
            "Epoch 144/1000\n",
            "36/36 - 4s - loss: 1.9020 - mae: 1.9020 - val_loss: 1.9028 - val_mae: 1.9028\n",
            "Epoch 145/1000\n",
            "36/36 - 4s - loss: 2.0045 - mae: 2.0045 - val_loss: 1.8585 - val_mae: 1.8585\n",
            "Epoch 146/1000\n",
            "36/36 - 4s - loss: 1.8944 - mae: 1.8944 - val_loss: 2.2289 - val_mae: 2.2289\n",
            "Epoch 147/1000\n",
            "36/36 - 4s - loss: 1.9631 - mae: 1.9631 - val_loss: 2.1569 - val_mae: 2.1569\n",
            "Epoch 148/1000\n",
            "36/36 - 4s - loss: 1.9288 - mae: 1.9288 - val_loss: 2.0940 - val_mae: 2.0940\n",
            "Epoch 149/1000\n",
            "36/36 - 4s - loss: 2.0122 - mae: 2.0122 - val_loss: 1.8790 - val_mae: 1.8790\n",
            "Epoch 150/1000\n",
            "36/36 - 4s - loss: 1.9097 - mae: 1.9097 - val_loss: 1.9496 - val_mae: 1.9496\n",
            "Epoch 151/1000\n",
            "36/36 - 4s - loss: 1.8943 - mae: 1.8943 - val_loss: 1.9067 - val_mae: 1.9067\n",
            "Epoch 152/1000\n",
            "36/36 - 4s - loss: 1.8614 - mae: 1.8614 - val_loss: 1.7763 - val_mae: 1.7763\n",
            "Epoch 153/1000\n",
            "36/36 - 4s - loss: 1.8057 - mae: 1.8057 - val_loss: 1.7871 - val_mae: 1.7871\n",
            "Epoch 154/1000\n",
            "36/36 - 4s - loss: 1.8494 - mae: 1.8494 - val_loss: 1.8530 - val_mae: 1.8530\n",
            "Epoch 155/1000\n",
            "36/36 - 4s - loss: 1.8995 - mae: 1.8995 - val_loss: 2.0055 - val_mae: 2.0055\n",
            "Epoch 156/1000\n",
            "36/36 - 4s - loss: 1.8523 - mae: 1.8523 - val_loss: 1.9447 - val_mae: 1.9447\n",
            "Epoch 157/1000\n",
            "36/36 - 4s - loss: 1.8294 - mae: 1.8294 - val_loss: 1.7784 - val_mae: 1.7784\n",
            "Epoch 158/1000\n",
            "36/36 - 4s - loss: 1.7811 - mae: 1.7811 - val_loss: 1.9097 - val_mae: 1.9097\n",
            "Epoch 159/1000\n",
            "36/36 - 4s - loss: 1.9534 - mae: 1.9534 - val_loss: 1.9603 - val_mae: 1.9603\n",
            "Epoch 160/1000\n",
            "36/36 - 4s - loss: 1.8513 - mae: 1.8513 - val_loss: 1.8443 - val_mae: 1.8443\n",
            "Epoch 161/1000\n",
            "36/36 - 4s - loss: 1.8271 - mae: 1.8271 - val_loss: 1.8094 - val_mae: 1.8094\n",
            "Epoch 162/1000\n",
            "36/36 - 4s - loss: 1.8091 - mae: 1.8091 - val_loss: 1.6707 - val_mae: 1.6707\n",
            "Epoch 163/1000\n",
            "36/36 - 4s - loss: 1.7815 - mae: 1.7815 - val_loss: 1.7452 - val_mae: 1.7452\n",
            "Epoch 164/1000\n",
            "36/36 - 4s - loss: 1.7869 - mae: 1.7869 - val_loss: 1.8620 - val_mae: 1.8620\n",
            "Epoch 165/1000\n",
            "36/36 - 4s - loss: 1.8897 - mae: 1.8897 - val_loss: 1.9135 - val_mae: 1.9135\n",
            "Epoch 166/1000\n",
            "36/36 - 4s - loss: 1.7654 - mae: 1.7654 - val_loss: 1.7238 - val_mae: 1.7238\n",
            "Epoch 167/1000\n",
            "36/36 - 4s - loss: 1.7578 - mae: 1.7578 - val_loss: 1.7025 - val_mae: 1.7025\n",
            "Epoch 168/1000\n",
            "36/36 - 4s - loss: 1.8417 - mae: 1.8417 - val_loss: 1.7635 - val_mae: 1.7635\n",
            "Epoch 169/1000\n",
            "36/36 - 4s - loss: 1.8795 - mae: 1.8795 - val_loss: 1.6698 - val_mae: 1.6698\n",
            "Epoch 170/1000\n",
            "36/36 - 4s - loss: 1.7962 - mae: 1.7962 - val_loss: 1.7541 - val_mae: 1.7541\n",
            "Epoch 171/1000\n",
            "36/36 - 4s - loss: 1.7724 - mae: 1.7724 - val_loss: 1.6689 - val_mae: 1.6689\n",
            "Epoch 172/1000\n",
            "36/36 - 4s - loss: 1.7759 - mae: 1.7759 - val_loss: 1.7429 - val_mae: 1.7429\n",
            "Epoch 173/1000\n",
            "36/36 - 4s - loss: 1.8135 - mae: 1.8135 - val_loss: 1.7987 - val_mae: 1.7987\n",
            "Epoch 174/1000\n",
            "36/36 - 4s - loss: 1.6982 - mae: 1.6982 - val_loss: 1.6226 - val_mae: 1.6226\n",
            "Epoch 175/1000\n",
            "36/36 - 4s - loss: 1.7468 - mae: 1.7468 - val_loss: 1.7491 - val_mae: 1.7491\n",
            "Epoch 176/1000\n",
            "36/36 - 4s - loss: 1.7103 - mae: 1.7103 - val_loss: 1.6998 - val_mae: 1.6998\n",
            "Epoch 177/1000\n",
            "36/36 - 4s - loss: 1.7859 - mae: 1.7859 - val_loss: 1.7088 - val_mae: 1.7088\n",
            "Epoch 178/1000\n",
            "36/36 - 4s - loss: 1.8332 - mae: 1.8332 - val_loss: 1.8640 - val_mae: 1.8640\n",
            "Epoch 179/1000\n",
            "36/36 - 4s - loss: 1.7542 - mae: 1.7542 - val_loss: 1.7409 - val_mae: 1.7409\n",
            "Epoch 180/1000\n",
            "36/36 - 4s - loss: 1.7492 - mae: 1.7492 - val_loss: 1.8475 - val_mae: 1.8475\n",
            "Epoch 181/1000\n",
            "36/36 - 4s - loss: 1.7436 - mae: 1.7436 - val_loss: 1.6806 - val_mae: 1.6806\n",
            "Epoch 182/1000\n",
            "36/36 - 4s - loss: 1.7807 - mae: 1.7807 - val_loss: 1.7962 - val_mae: 1.7962\n",
            "Epoch 183/1000\n",
            "36/36 - 4s - loss: 1.7950 - mae: 1.7950 - val_loss: 1.6003 - val_mae: 1.6003\n",
            "Epoch 184/1000\n",
            "36/36 - 4s - loss: 1.7344 - mae: 1.7344 - val_loss: 1.6171 - val_mae: 1.6171\n",
            "Epoch 185/1000\n",
            "36/36 - 4s - loss: 1.6826 - mae: 1.6826 - val_loss: 1.7766 - val_mae: 1.7766\n",
            "Epoch 186/1000\n",
            "36/36 - 4s - loss: 1.8799 - mae: 1.8799 - val_loss: 1.8748 - val_mae: 1.8748\n",
            "Epoch 187/1000\n",
            "36/36 - 4s - loss: 1.7481 - mae: 1.7481 - val_loss: 1.6714 - val_mae: 1.6714\n",
            "Epoch 188/1000\n",
            "36/36 - 4s - loss: 1.7068 - mae: 1.7068 - val_loss: 1.4870 - val_mae: 1.4870\n",
            "Epoch 189/1000\n",
            "36/36 - 4s - loss: 1.7075 - mae: 1.7075 - val_loss: 1.6225 - val_mae: 1.6225\n",
            "Epoch 190/1000\n",
            "36/36 - 4s - loss: 1.6685 - mae: 1.6685 - val_loss: 1.6205 - val_mae: 1.6205\n",
            "Epoch 191/1000\n",
            "36/36 - 4s - loss: 1.8226 - mae: 1.8226 - val_loss: 1.9277 - val_mae: 1.9277\n",
            "Epoch 192/1000\n",
            "36/36 - 4s - loss: 1.8234 - mae: 1.8234 - val_loss: 1.8162 - val_mae: 1.8162\n",
            "Epoch 193/1000\n",
            "36/36 - 4s - loss: 1.7771 - mae: 1.7771 - val_loss: 1.5885 - val_mae: 1.5885\n",
            "Epoch 194/1000\n",
            "36/36 - 4s - loss: 1.7076 - mae: 1.7076 - val_loss: 1.6100 - val_mae: 1.6100\n",
            "Epoch 195/1000\n",
            "36/36 - 4s - loss: 1.7128 - mae: 1.7128 - val_loss: 1.6389 - val_mae: 1.6389\n",
            "Epoch 196/1000\n",
            "36/36 - 4s - loss: 1.7795 - mae: 1.7795 - val_loss: 1.7050 - val_mae: 1.7050\n",
            "Epoch 197/1000\n",
            "36/36 - 4s - loss: 1.6766 - mae: 1.6766 - val_loss: 1.7251 - val_mae: 1.7251\n",
            "Epoch 198/1000\n",
            "36/36 - 4s - loss: 1.7194 - mae: 1.7194 - val_loss: 1.5984 - val_mae: 1.5984\n",
            "Epoch 199/1000\n",
            "36/36 - 4s - loss: 1.8174 - mae: 1.8174 - val_loss: 1.6501 - val_mae: 1.6501\n",
            "Epoch 200/1000\n",
            "36/36 - 4s - loss: 1.7310 - mae: 1.7310 - val_loss: 1.7767 - val_mae: 1.7767\n",
            "Epoch 201/1000\n",
            "36/36 - 4s - loss: 1.8247 - mae: 1.8247 - val_loss: 1.8499 - val_mae: 1.8499\n",
            "Epoch 202/1000\n",
            "36/36 - 4s - loss: 1.6663 - mae: 1.6663 - val_loss: 1.7832 - val_mae: 1.7832\n",
            "Epoch 203/1000\n",
            "36/36 - 4s - loss: 1.7675 - mae: 1.7675 - val_loss: 1.6434 - val_mae: 1.6434\n",
            "Epoch 204/1000\n",
            "36/36 - 4s - loss: 1.6592 - mae: 1.6592 - val_loss: 1.7131 - val_mae: 1.7131\n",
            "Epoch 205/1000\n",
            "36/36 - 4s - loss: 1.6904 - mae: 1.6904 - val_loss: 1.6704 - val_mae: 1.6704\n",
            "Epoch 206/1000\n",
            "36/36 - 4s - loss: 1.6745 - mae: 1.6745 - val_loss: 1.6307 - val_mae: 1.6307\n",
            "Epoch 207/1000\n",
            "36/36 - 4s - loss: 1.6196 - mae: 1.6196 - val_loss: 1.4767 - val_mae: 1.4767\n",
            "Epoch 208/1000\n",
            "36/36 - 4s - loss: 1.5833 - mae: 1.5833 - val_loss: 1.5745 - val_mae: 1.5745\n",
            "Epoch 209/1000\n",
            "36/36 - 4s - loss: 1.6562 - mae: 1.6562 - val_loss: 1.6088 - val_mae: 1.6088\n",
            "Epoch 210/1000\n",
            "36/36 - 4s - loss: 1.8143 - mae: 1.8143 - val_loss: 1.6913 - val_mae: 1.6913\n",
            "Epoch 211/1000\n",
            "36/36 - 4s - loss: 1.6847 - mae: 1.6847 - val_loss: 1.6167 - val_mae: 1.6167\n",
            "Epoch 212/1000\n",
            "36/36 - 4s - loss: 1.5694 - mae: 1.5694 - val_loss: 1.5485 - val_mae: 1.5485\n",
            "Epoch 213/1000\n",
            "36/36 - 4s - loss: 1.5815 - mae: 1.5815 - val_loss: 1.4897 - val_mae: 1.4897\n",
            "Epoch 214/1000\n",
            "36/36 - 4s - loss: 1.6964 - mae: 1.6964 - val_loss: 1.6936 - val_mae: 1.6936\n",
            "Epoch 215/1000\n",
            "36/36 - 4s - loss: 1.7423 - mae: 1.7423 - val_loss: 1.7231 - val_mae: 1.7231\n",
            "Epoch 216/1000\n",
            "36/36 - 4s - loss: 1.7211 - mae: 1.7211 - val_loss: 1.6211 - val_mae: 1.6211\n",
            "Epoch 217/1000\n",
            "36/36 - 4s - loss: 1.6702 - mae: 1.6702 - val_loss: 1.5421 - val_mae: 1.5421\n",
            "Epoch 218/1000\n",
            "36/36 - 4s - loss: 1.6704 - mae: 1.6704 - val_loss: 1.4164 - val_mae: 1.4164\n",
            "Epoch 219/1000\n",
            "36/36 - 4s - loss: 1.6287 - mae: 1.6287 - val_loss: 1.6187 - val_mae: 1.6187\n",
            "Epoch 220/1000\n",
            "36/36 - 4s - loss: 1.6968 - mae: 1.6968 - val_loss: 1.9942 - val_mae: 1.9942\n",
            "Epoch 221/1000\n",
            "36/36 - 4s - loss: 1.7876 - mae: 1.7876 - val_loss: 1.7519 - val_mae: 1.7519\n",
            "Epoch 222/1000\n",
            "36/36 - 4s - loss: 1.7030 - mae: 1.7030 - val_loss: 1.5778 - val_mae: 1.5778\n",
            "Epoch 223/1000\n",
            "36/36 - 4s - loss: 1.6487 - mae: 1.6487 - val_loss: 1.5659 - val_mae: 1.5659\n",
            "Epoch 224/1000\n",
            "36/36 - 4s - loss: 1.6763 - mae: 1.6763 - val_loss: 1.6365 - val_mae: 1.6365\n",
            "Epoch 225/1000\n",
            "36/36 - 4s - loss: 1.6396 - mae: 1.6396 - val_loss: 1.6679 - val_mae: 1.6679\n",
            "Epoch 226/1000\n",
            "36/36 - 4s - loss: 1.7100 - mae: 1.7100 - val_loss: 1.4624 - val_mae: 1.4624\n",
            "Epoch 227/1000\n",
            "36/36 - 4s - loss: 1.6353 - mae: 1.6353 - val_loss: 1.4364 - val_mae: 1.4364\n",
            "Epoch 228/1000\n",
            "36/36 - 4s - loss: 1.6781 - mae: 1.6781 - val_loss: 1.5052 - val_mae: 1.5052\n",
            "Epoch 229/1000\n",
            "36/36 - 4s - loss: 1.6408 - mae: 1.6408 - val_loss: 1.4793 - val_mae: 1.4793\n",
            "Epoch 230/1000\n",
            "36/36 - 4s - loss: 1.7103 - mae: 1.7103 - val_loss: 1.5947 - val_mae: 1.5947\n",
            "Epoch 231/1000\n",
            "36/36 - 4s - loss: 1.6116 - mae: 1.6116 - val_loss: 1.4922 - val_mae: 1.4922\n",
            "Epoch 232/1000\n",
            "36/36 - 4s - loss: 1.7162 - mae: 1.7162 - val_loss: 1.5985 - val_mae: 1.5985\n",
            "Epoch 233/1000\n",
            "36/36 - 4s - loss: 1.7112 - mae: 1.7112 - val_loss: 1.8214 - val_mae: 1.8214\n",
            "Epoch 234/1000\n",
            "36/36 - 4s - loss: 1.6247 - mae: 1.6247 - val_loss: 1.6933 - val_mae: 1.6933\n",
            "Epoch 235/1000\n",
            "36/36 - 4s - loss: 1.5424 - mae: 1.5424 - val_loss: 1.4137 - val_mae: 1.4137\n",
            "Epoch 236/1000\n",
            "36/36 - 4s - loss: 1.5701 - mae: 1.5701 - val_loss: 1.5485 - val_mae: 1.5485\n",
            "Epoch 237/1000\n",
            "36/36 - 4s - loss: 1.5784 - mae: 1.5784 - val_loss: 1.3657 - val_mae: 1.3657\n",
            "Epoch 238/1000\n",
            "36/36 - 4s - loss: 1.5054 - mae: 1.5054 - val_loss: 1.4463 - val_mae: 1.4463\n",
            "Epoch 239/1000\n",
            "36/36 - 4s - loss: 1.6050 - mae: 1.6050 - val_loss: 1.6883 - val_mae: 1.6883\n",
            "Epoch 240/1000\n",
            "36/36 - 4s - loss: 1.6649 - mae: 1.6649 - val_loss: 1.6205 - val_mae: 1.6205\n",
            "Epoch 241/1000\n",
            "36/36 - 4s - loss: 1.6084 - mae: 1.6084 - val_loss: 1.4961 - val_mae: 1.4961\n",
            "Epoch 242/1000\n",
            "36/36 - 4s - loss: 1.6004 - mae: 1.6004 - val_loss: 1.5033 - val_mae: 1.5033\n",
            "Epoch 243/1000\n",
            "36/36 - 4s - loss: 1.6225 - mae: 1.6225 - val_loss: 1.6283 - val_mae: 1.6283\n",
            "Epoch 244/1000\n",
            "36/36 - 4s - loss: 1.6499 - mae: 1.6499 - val_loss: 1.4690 - val_mae: 1.4690\n",
            "Epoch 245/1000\n",
            "36/36 - 4s - loss: 1.7016 - mae: 1.7016 - val_loss: 1.3932 - val_mae: 1.3932\n",
            "Epoch 246/1000\n",
            "36/36 - 4s - loss: 1.6818 - mae: 1.6818 - val_loss: 1.6222 - val_mae: 1.6222\n",
            "Epoch 247/1000\n",
            "36/36 - 4s - loss: 1.6543 - mae: 1.6543 - val_loss: 1.5546 - val_mae: 1.5546\n",
            "Epoch 248/1000\n",
            "36/36 - 4s - loss: 1.6090 - mae: 1.6090 - val_loss: 1.3952 - val_mae: 1.3952\n",
            "Epoch 249/1000\n",
            "36/36 - 4s - loss: 1.5284 - mae: 1.5284 - val_loss: 1.4051 - val_mae: 1.4051\n",
            "Epoch 250/1000\n",
            "36/36 - 4s - loss: 1.5723 - mae: 1.5723 - val_loss: 1.4489 - val_mae: 1.4489\n",
            "Epoch 251/1000\n",
            "36/36 - 4s - loss: 1.5568 - mae: 1.5568 - val_loss: 1.4218 - val_mae: 1.4218\n",
            "Epoch 252/1000\n",
            "36/36 - 4s - loss: 1.5991 - mae: 1.5991 - val_loss: 1.3581 - val_mae: 1.3581\n",
            "Epoch 253/1000\n",
            "36/36 - 4s - loss: 1.6272 - mae: 1.6272 - val_loss: 1.4404 - val_mae: 1.4404\n",
            "Epoch 254/1000\n",
            "36/36 - 4s - loss: 1.5843 - mae: 1.5843 - val_loss: 1.3376 - val_mae: 1.3376\n",
            "Epoch 255/1000\n",
            "36/36 - 4s - loss: 1.6312 - mae: 1.6312 - val_loss: 1.4896 - val_mae: 1.4896\n",
            "Epoch 256/1000\n",
            "36/36 - 4s - loss: 1.5765 - mae: 1.5765 - val_loss: 1.5588 - val_mae: 1.5588\n",
            "Epoch 257/1000\n",
            "36/36 - 4s - loss: 1.6332 - mae: 1.6332 - val_loss: 1.4765 - val_mae: 1.4765\n",
            "Epoch 258/1000\n",
            "36/36 - 4s - loss: 1.5842 - mae: 1.5842 - val_loss: 1.4886 - val_mae: 1.4886\n",
            "Epoch 259/1000\n",
            "36/36 - 4s - loss: 1.6316 - mae: 1.6316 - val_loss: 1.5510 - val_mae: 1.5510\n",
            "Epoch 260/1000\n",
            "36/36 - 5s - loss: 1.5566 - mae: 1.5566 - val_loss: 1.4189 - val_mae: 1.4189\n",
            "Epoch 261/1000\n",
            "36/36 - 4s - loss: 1.4996 - mae: 1.4996 - val_loss: 1.4842 - val_mae: 1.4842\n",
            "Epoch 262/1000\n",
            "36/36 - 4s - loss: 1.5147 - mae: 1.5147 - val_loss: 1.5530 - val_mae: 1.5530\n",
            "Epoch 263/1000\n",
            "36/36 - 4s - loss: 1.6687 - mae: 1.6687 - val_loss: 1.3219 - val_mae: 1.3219\n",
            "Epoch 264/1000\n",
            "36/36 - 4s - loss: 1.5137 - mae: 1.5137 - val_loss: 1.5760 - val_mae: 1.5760\n",
            "Epoch 265/1000\n",
            "36/36 - 4s - loss: 1.6543 - mae: 1.6543 - val_loss: 1.5364 - val_mae: 1.5364\n",
            "Epoch 266/1000\n",
            "36/36 - 4s - loss: 1.5336 - mae: 1.5336 - val_loss: 1.3889 - val_mae: 1.3889\n",
            "Epoch 267/1000\n",
            "36/36 - 4s - loss: 1.5731 - mae: 1.5731 - val_loss: 1.4427 - val_mae: 1.4427\n",
            "Epoch 268/1000\n",
            "36/36 - 4s - loss: 1.5429 - mae: 1.5429 - val_loss: 1.5538 - val_mae: 1.5538\n",
            "Epoch 269/1000\n",
            "36/36 - 4s - loss: 1.5391 - mae: 1.5391 - val_loss: 1.6199 - val_mae: 1.6199\n",
            "Epoch 270/1000\n",
            "36/36 - 4s - loss: 1.5803 - mae: 1.5803 - val_loss: 1.4083 - val_mae: 1.4083\n",
            "Epoch 271/1000\n",
            "36/36 - 4s - loss: 1.4939 - mae: 1.4939 - val_loss: 1.4491 - val_mae: 1.4491\n",
            "Epoch 272/1000\n",
            "36/36 - 4s - loss: 1.6050 - mae: 1.6050 - val_loss: 1.3188 - val_mae: 1.3188\n",
            "Epoch 273/1000\n",
            "36/36 - 4s - loss: 1.4973 - mae: 1.4973 - val_loss: 1.4010 - val_mae: 1.4010\n",
            "Epoch 274/1000\n",
            "36/36 - 4s - loss: 1.5076 - mae: 1.5076 - val_loss: 1.4534 - val_mae: 1.4534\n",
            "Epoch 275/1000\n",
            "36/36 - 4s - loss: 1.5773 - mae: 1.5773 - val_loss: 1.3885 - val_mae: 1.3885\n",
            "Epoch 276/1000\n",
            "36/36 - 4s - loss: 1.5722 - mae: 1.5722 - val_loss: 1.5381 - val_mae: 1.5381\n",
            "Epoch 277/1000\n",
            "36/36 - 4s - loss: 1.5776 - mae: 1.5776 - val_loss: 1.5444 - val_mae: 1.5444\n",
            "Epoch 278/1000\n",
            "36/36 - 4s - loss: 1.5684 - mae: 1.5684 - val_loss: 1.4338 - val_mae: 1.4338\n",
            "Epoch 279/1000\n",
            "36/36 - 4s - loss: 1.4562 - mae: 1.4562 - val_loss: 1.2490 - val_mae: 1.2490\n",
            "Epoch 280/1000\n",
            "36/36 - 4s - loss: 1.4894 - mae: 1.4894 - val_loss: 1.4213 - val_mae: 1.4213\n",
            "Epoch 281/1000\n",
            "36/36 - 4s - loss: 1.5565 - mae: 1.5565 - val_loss: 1.3998 - val_mae: 1.3998\n",
            "Epoch 282/1000\n",
            "36/36 - 4s - loss: 1.4638 - mae: 1.4638 - val_loss: 1.4241 - val_mae: 1.4241\n",
            "Epoch 283/1000\n",
            "36/36 - 4s - loss: 1.4797 - mae: 1.4797 - val_loss: 1.4754 - val_mae: 1.4754\n",
            "Epoch 284/1000\n",
            "36/36 - 4s - loss: 1.6126 - mae: 1.6126 - val_loss: 1.4712 - val_mae: 1.4712\n",
            "Epoch 285/1000\n",
            "36/36 - 4s - loss: 1.5671 - mae: 1.5671 - val_loss: 1.4739 - val_mae: 1.4739\n",
            "Epoch 286/1000\n",
            "36/36 - 4s - loss: 1.5839 - mae: 1.5839 - val_loss: 1.3305 - val_mae: 1.3305\n",
            "Epoch 287/1000\n",
            "36/36 - 4s - loss: 1.5198 - mae: 1.5198 - val_loss: 1.3420 - val_mae: 1.3420\n",
            "Epoch 288/1000\n",
            "36/36 - 4s - loss: 1.5481 - mae: 1.5481 - val_loss: 1.4349 - val_mae: 1.4349\n",
            "Epoch 289/1000\n",
            "36/36 - 4s - loss: 1.5126 - mae: 1.5126 - val_loss: 1.6177 - val_mae: 1.6177\n",
            "Epoch 290/1000\n",
            "36/36 - 4s - loss: 1.4456 - mae: 1.4456 - val_loss: 1.3114 - val_mae: 1.3114\n",
            "Epoch 291/1000\n",
            "36/36 - 4s - loss: 1.4665 - mae: 1.4665 - val_loss: 1.3657 - val_mae: 1.3657\n",
            "Epoch 292/1000\n",
            "36/36 - 4s - loss: 1.5051 - mae: 1.5051 - val_loss: 1.5466 - val_mae: 1.5466\n",
            "Epoch 293/1000\n",
            "36/36 - 4s - loss: 1.5426 - mae: 1.5426 - val_loss: 1.3588 - val_mae: 1.3588\n",
            "Epoch 294/1000\n",
            "36/36 - 4s - loss: 1.5194 - mae: 1.5194 - val_loss: 1.2562 - val_mae: 1.2562\n",
            "Epoch 295/1000\n",
            "36/36 - 4s - loss: 1.5428 - mae: 1.5428 - val_loss: 1.4546 - val_mae: 1.4546\n",
            "Epoch 296/1000\n",
            "36/36 - 4s - loss: 1.5395 - mae: 1.5395 - val_loss: 1.5070 - val_mae: 1.5070\n",
            "Epoch 297/1000\n",
            "36/36 - 4s - loss: 1.4836 - mae: 1.4836 - val_loss: 1.3731 - val_mae: 1.3731\n",
            "Epoch 298/1000\n",
            "36/36 - 4s - loss: 1.4783 - mae: 1.4783 - val_loss: 1.2655 - val_mae: 1.2655\n",
            "Epoch 299/1000\n",
            "36/36 - 4s - loss: 1.5022 - mae: 1.5022 - val_loss: 1.5161 - val_mae: 1.5161\n",
            "Epoch 300/1000\n",
            "36/36 - 4s - loss: 1.5361 - mae: 1.5361 - val_loss: 1.5203 - val_mae: 1.5203\n",
            "Epoch 301/1000\n",
            "36/36 - 4s - loss: 1.4107 - mae: 1.4107 - val_loss: 1.2986 - val_mae: 1.2986\n",
            "Epoch 302/1000\n",
            "36/36 - 4s - loss: 1.5079 - mae: 1.5079 - val_loss: 1.4066 - val_mae: 1.4066\n",
            "Epoch 303/1000\n",
            "36/36 - 4s - loss: 1.4584 - mae: 1.4584 - val_loss: 1.4029 - val_mae: 1.4029\n",
            "Epoch 304/1000\n",
            "36/36 - 4s - loss: 1.4887 - mae: 1.4887 - val_loss: 1.5771 - val_mae: 1.5771\n",
            "Epoch 305/1000\n",
            "36/36 - 4s - loss: 1.5500 - mae: 1.5500 - val_loss: 1.5748 - val_mae: 1.5748\n",
            "Epoch 306/1000\n",
            "36/36 - 4s - loss: 1.5098 - mae: 1.5098 - val_loss: 1.3121 - val_mae: 1.3121\n",
            "Epoch 307/1000\n",
            "36/36 - 4s - loss: 1.5790 - mae: 1.5790 - val_loss: 1.3346 - val_mae: 1.3346\n",
            "Epoch 308/1000\n",
            "36/36 - 4s - loss: 1.4846 - mae: 1.4846 - val_loss: 1.2866 - val_mae: 1.2866\n",
            "Epoch 309/1000\n",
            "36/36 - 4s - loss: 1.4470 - mae: 1.4470 - val_loss: 1.3119 - val_mae: 1.3119\n",
            "Epoch 310/1000\n",
            "36/36 - 4s - loss: 1.4710 - mae: 1.4710 - val_loss: 1.4873 - val_mae: 1.4873\n",
            "Epoch 311/1000\n",
            "36/36 - 4s - loss: 1.4784 - mae: 1.4784 - val_loss: 1.2809 - val_mae: 1.2809\n",
            "Epoch 312/1000\n",
            "36/36 - 4s - loss: 1.4905 - mae: 1.4905 - val_loss: 1.3118 - val_mae: 1.3118\n",
            "Epoch 313/1000\n",
            "36/36 - 4s - loss: 1.4791 - mae: 1.4791 - val_loss: 1.3250 - val_mae: 1.3250\n",
            "Epoch 314/1000\n",
            "36/36 - 4s - loss: 1.5303 - mae: 1.5303 - val_loss: 1.3094 - val_mae: 1.3094\n",
            "Epoch 315/1000\n",
            "36/36 - 4s - loss: 1.5139 - mae: 1.5139 - val_loss: 1.6028 - val_mae: 1.6028\n",
            "Epoch 316/1000\n",
            "36/36 - 4s - loss: 1.5058 - mae: 1.5058 - val_loss: 1.5003 - val_mae: 1.5003\n",
            "Epoch 317/1000\n",
            "36/36 - 4s - loss: 1.5044 - mae: 1.5044 - val_loss: 1.2992 - val_mae: 1.2992\n",
            "Epoch 318/1000\n",
            "36/36 - 4s - loss: 1.4003 - mae: 1.4003 - val_loss: 1.3486 - val_mae: 1.3486\n",
            "Epoch 319/1000\n",
            "36/36 - 4s - loss: 1.3410 - mae: 1.3410 - val_loss: 1.2673 - val_mae: 1.2673\n",
            "Epoch 320/1000\n",
            "36/36 - 4s - loss: 1.4030 - mae: 1.4030 - val_loss: 1.4829 - val_mae: 1.4829\n",
            "Epoch 321/1000\n",
            "36/36 - 4s - loss: 1.4065 - mae: 1.4065 - val_loss: 1.3217 - val_mae: 1.3217\n",
            "Epoch 322/1000\n",
            "36/36 - 4s - loss: 1.3708 - mae: 1.3708 - val_loss: 1.3843 - val_mae: 1.3843\n",
            "Epoch 323/1000\n",
            "36/36 - 4s - loss: 1.4100 - mae: 1.4100 - val_loss: 1.2643 - val_mae: 1.2643\n",
            "Epoch 324/1000\n",
            "36/36 - 4s - loss: 1.4444 - mae: 1.4444 - val_loss: 1.3048 - val_mae: 1.3048\n",
            "Epoch 325/1000\n",
            "36/36 - 4s - loss: 1.4478 - mae: 1.4478 - val_loss: 1.2871 - val_mae: 1.2871\n",
            "Epoch 326/1000\n",
            "36/36 - 4s - loss: 1.4429 - mae: 1.4429 - val_loss: 1.2427 - val_mae: 1.2427\n",
            "Epoch 327/1000\n",
            "36/36 - 4s - loss: 1.5391 - mae: 1.5391 - val_loss: 1.3016 - val_mae: 1.3016\n",
            "Epoch 328/1000\n",
            "36/36 - 4s - loss: 1.4177 - mae: 1.4177 - val_loss: 1.3615 - val_mae: 1.3615\n",
            "Epoch 329/1000\n",
            "36/36 - 4s - loss: 1.3748 - mae: 1.3748 - val_loss: 1.3109 - val_mae: 1.3109\n",
            "Epoch 330/1000\n",
            "36/36 - 4s - loss: 1.4735 - mae: 1.4735 - val_loss: 1.2639 - val_mae: 1.2639\n",
            "Epoch 331/1000\n",
            "36/36 - 4s - loss: 1.4171 - mae: 1.4171 - val_loss: 1.3181 - val_mae: 1.3181\n",
            "Epoch 332/1000\n",
            "36/36 - 4s - loss: 1.4184 - mae: 1.4184 - val_loss: 1.3271 - val_mae: 1.3271\n",
            "Epoch 333/1000\n",
            "36/36 - 4s - loss: 1.3903 - mae: 1.3903 - val_loss: 1.2522 - val_mae: 1.2522\n",
            "Epoch 334/1000\n",
            "36/36 - 4s - loss: 1.3845 - mae: 1.3845 - val_loss: 1.3446 - val_mae: 1.3446\n",
            "Epoch 335/1000\n",
            "36/36 - 4s - loss: 1.4362 - mae: 1.4362 - val_loss: 1.2604 - val_mae: 1.2604\n",
            "Epoch 336/1000\n",
            "36/36 - 4s - loss: 1.4273 - mae: 1.4273 - val_loss: 1.3802 - val_mae: 1.3802\n",
            "Epoch 337/1000\n",
            "36/36 - 4s - loss: 1.5033 - mae: 1.5033 - val_loss: 1.4159 - val_mae: 1.4159\n",
            "Epoch 338/1000\n",
            "36/36 - 4s - loss: 1.4514 - mae: 1.4514 - val_loss: 1.2965 - val_mae: 1.2965\n",
            "Epoch 339/1000\n",
            "36/36 - 4s - loss: 1.4647 - mae: 1.4647 - val_loss: 1.3194 - val_mae: 1.3194\n",
            "Epoch 340/1000\n",
            "36/36 - 4s - loss: 1.4457 - mae: 1.4457 - val_loss: 1.2058 - val_mae: 1.2058\n",
            "Epoch 341/1000\n",
            "36/36 - 4s - loss: 1.4332 - mae: 1.4332 - val_loss: 1.3716 - val_mae: 1.3716\n",
            "Epoch 342/1000\n",
            "36/36 - 4s - loss: 1.4802 - mae: 1.4802 - val_loss: 1.4208 - val_mae: 1.4208\n",
            "Epoch 343/1000\n",
            "36/36 - 4s - loss: 1.4021 - mae: 1.4021 - val_loss: 1.1811 - val_mae: 1.1811\n",
            "Epoch 344/1000\n",
            "36/36 - 4s - loss: 1.3933 - mae: 1.3933 - val_loss: 1.3909 - val_mae: 1.3909\n",
            "Epoch 345/1000\n",
            "36/36 - 4s - loss: 1.4434 - mae: 1.4434 - val_loss: 1.3175 - val_mae: 1.3175\n",
            "Epoch 346/1000\n",
            "36/36 - 4s - loss: 1.4716 - mae: 1.4716 - val_loss: 1.3010 - val_mae: 1.3010\n",
            "Epoch 347/1000\n",
            "36/36 - 4s - loss: 1.4539 - mae: 1.4539 - val_loss: 1.3465 - val_mae: 1.3465\n",
            "Epoch 348/1000\n",
            "36/36 - 4s - loss: 1.4993 - mae: 1.4993 - val_loss: 1.2274 - val_mae: 1.2274\n",
            "Epoch 349/1000\n",
            "36/36 - 4s - loss: 1.4398 - mae: 1.4398 - val_loss: 1.4131 - val_mae: 1.4131\n",
            "Epoch 350/1000\n",
            "36/36 - 4s - loss: 1.3375 - mae: 1.3375 - val_loss: 1.1333 - val_mae: 1.1333\n",
            "Epoch 351/1000\n",
            "36/36 - 4s - loss: 1.4316 - mae: 1.4316 - val_loss: 1.4304 - val_mae: 1.4304\n",
            "Epoch 352/1000\n",
            "36/36 - 4s - loss: 1.3918 - mae: 1.3918 - val_loss: 1.5542 - val_mae: 1.5542\n",
            "Epoch 353/1000\n",
            "36/36 - 4s - loss: 1.3923 - mae: 1.3923 - val_loss: 1.2620 - val_mae: 1.2620\n",
            "Epoch 354/1000\n",
            "36/36 - 4s - loss: 1.4161 - mae: 1.4161 - val_loss: 1.2663 - val_mae: 1.2663\n",
            "Epoch 355/1000\n",
            "36/36 - 4s - loss: 1.4342 - mae: 1.4342 - val_loss: 1.4026 - val_mae: 1.4026\n",
            "Epoch 356/1000\n",
            "36/36 - 4s - loss: 1.3724 - mae: 1.3724 - val_loss: 1.3711 - val_mae: 1.3711\n",
            "Epoch 357/1000\n",
            "36/36 - 4s - loss: 1.3507 - mae: 1.3507 - val_loss: 1.2613 - val_mae: 1.2613\n",
            "Epoch 358/1000\n",
            "36/36 - 4s - loss: 1.3833 - mae: 1.3833 - val_loss: 1.3767 - val_mae: 1.3767\n",
            "Epoch 359/1000\n",
            "36/36 - 4s - loss: 1.3575 - mae: 1.3575 - val_loss: 1.2175 - val_mae: 1.2175\n",
            "Epoch 360/1000\n",
            "36/36 - 4s - loss: 1.3301 - mae: 1.3301 - val_loss: 1.2574 - val_mae: 1.2574\n",
            "Epoch 361/1000\n",
            "36/36 - 4s - loss: 1.4852 - mae: 1.4852 - val_loss: 1.2251 - val_mae: 1.2251\n",
            "Epoch 362/1000\n",
            "36/36 - 4s - loss: 1.3426 - mae: 1.3426 - val_loss: 1.2232 - val_mae: 1.2232\n",
            "Epoch 363/1000\n",
            "36/36 - 4s - loss: 1.3166 - mae: 1.3166 - val_loss: 1.2720 - val_mae: 1.2720\n",
            "Epoch 364/1000\n",
            "36/36 - 4s - loss: 1.3314 - mae: 1.3314 - val_loss: 1.2757 - val_mae: 1.2757\n",
            "Epoch 365/1000\n",
            "36/36 - 4s - loss: 1.3870 - mae: 1.3870 - val_loss: 1.1761 - val_mae: 1.1761\n",
            "Epoch 366/1000\n",
            "36/36 - 4s - loss: 1.3657 - mae: 1.3657 - val_loss: 1.2108 - val_mae: 1.2108\n",
            "Epoch 367/1000\n",
            "36/36 - 4s - loss: 1.4060 - mae: 1.4060 - val_loss: 1.2171 - val_mae: 1.2171\n",
            "Epoch 368/1000\n",
            "36/36 - 4s - loss: 1.3033 - mae: 1.3033 - val_loss: 1.2234 - val_mae: 1.2234\n",
            "Epoch 369/1000\n",
            "36/36 - 4s - loss: 1.3380 - mae: 1.3380 - val_loss: 1.3751 - val_mae: 1.3751\n",
            "Epoch 370/1000\n",
            "36/36 - 4s - loss: 1.4504 - mae: 1.4504 - val_loss: 1.5281 - val_mae: 1.5281\n",
            "Epoch 371/1000\n",
            "36/36 - 4s - loss: 1.3568 - mae: 1.3568 - val_loss: 1.1726 - val_mae: 1.1726\n",
            "Epoch 372/1000\n",
            "36/36 - 4s - loss: 1.3417 - mae: 1.3417 - val_loss: 1.1345 - val_mae: 1.1345\n",
            "Epoch 373/1000\n",
            "36/36 - 4s - loss: 1.3278 - mae: 1.3278 - val_loss: 1.2371 - val_mae: 1.2371\n",
            "Epoch 374/1000\n",
            "36/36 - 4s - loss: 1.4319 - mae: 1.4319 - val_loss: 1.4427 - val_mae: 1.4427\n",
            "Epoch 375/1000\n",
            "36/36 - 4s - loss: 1.3756 - mae: 1.3756 - val_loss: 1.2649 - val_mae: 1.2649\n",
            "Epoch 376/1000\n",
            "36/36 - 4s - loss: 1.4386 - mae: 1.4386 - val_loss: 1.2063 - val_mae: 1.2063\n",
            "Epoch 377/1000\n",
            "36/36 - 4s - loss: 1.3590 - mae: 1.3590 - val_loss: 1.2193 - val_mae: 1.2193\n",
            "Epoch 378/1000\n",
            "36/36 - 4s - loss: 1.4455 - mae: 1.4455 - val_loss: 1.1691 - val_mae: 1.1691\n",
            "Epoch 379/1000\n",
            "36/36 - 4s - loss: 1.3725 - mae: 1.3725 - val_loss: 1.1357 - val_mae: 1.1357\n",
            "Epoch 380/1000\n",
            "36/36 - 4s - loss: 1.3869 - mae: 1.3869 - val_loss: 1.4939 - val_mae: 1.4939\n",
            "Epoch 381/1000\n",
            "36/36 - 4s - loss: 1.4088 - mae: 1.4088 - val_loss: 1.2313 - val_mae: 1.2313\n",
            "Epoch 382/1000\n",
            "36/36 - 4s - loss: 1.4014 - mae: 1.4014 - val_loss: 1.2230 - val_mae: 1.2230\n",
            "Epoch 383/1000\n",
            "36/36 - 4s - loss: 1.3464 - mae: 1.3464 - val_loss: 1.1696 - val_mae: 1.1696\n",
            "Epoch 384/1000\n",
            "36/36 - 4s - loss: 1.3442 - mae: 1.3442 - val_loss: 1.3781 - val_mae: 1.3781\n",
            "Epoch 385/1000\n",
            "36/36 - 4s - loss: 1.3395 - mae: 1.3395 - val_loss: 1.2675 - val_mae: 1.2675\n",
            "Epoch 386/1000\n",
            "36/36 - 4s - loss: 1.3313 - mae: 1.3313 - val_loss: 1.2705 - val_mae: 1.2705\n",
            "Epoch 387/1000\n",
            "36/36 - 4s - loss: 1.3614 - mae: 1.3614 - val_loss: 1.1927 - val_mae: 1.1927\n",
            "Epoch 388/1000\n",
            "36/36 - 4s - loss: 1.3258 - mae: 1.3258 - val_loss: 1.2429 - val_mae: 1.2429\n",
            "Epoch 389/1000\n",
            "36/36 - 4s - loss: 1.3402 - mae: 1.3402 - val_loss: 1.1460 - val_mae: 1.1460\n",
            "Epoch 390/1000\n",
            "36/36 - 4s - loss: 1.3684 - mae: 1.3684 - val_loss: 1.4075 - val_mae: 1.4075\n",
            "Epoch 391/1000\n",
            "36/36 - 4s - loss: 1.3685 - mae: 1.3685 - val_loss: 1.3116 - val_mae: 1.3116\n",
            "Epoch 392/1000\n",
            "36/36 - 4s - loss: 1.4632 - mae: 1.4632 - val_loss: 1.5110 - val_mae: 1.5110\n",
            "Epoch 393/1000\n",
            "36/36 - 4s - loss: 1.4910 - mae: 1.4910 - val_loss: 1.2265 - val_mae: 1.2265\n",
            "Epoch 394/1000\n",
            "36/36 - 4s - loss: 1.3773 - mae: 1.3773 - val_loss: 1.1149 - val_mae: 1.1149\n",
            "Epoch 395/1000\n",
            "36/36 - 4s - loss: 1.3606 - mae: 1.3606 - val_loss: 1.2754 - val_mae: 1.2754\n",
            "Epoch 396/1000\n",
            "36/36 - 4s - loss: 1.3143 - mae: 1.3143 - val_loss: 1.2595 - val_mae: 1.2595\n",
            "Epoch 397/1000\n",
            "36/36 - 4s - loss: 1.4155 - mae: 1.4155 - val_loss: 1.3618 - val_mae: 1.3618\n",
            "Epoch 398/1000\n",
            "36/36 - 4s - loss: 1.4109 - mae: 1.4109 - val_loss: 1.3265 - val_mae: 1.3265\n",
            "Epoch 399/1000\n",
            "36/36 - 4s - loss: 1.4909 - mae: 1.4909 - val_loss: 1.2549 - val_mae: 1.2549\n",
            "Epoch 400/1000\n",
            "36/36 - 4s - loss: 1.3472 - mae: 1.3472 - val_loss: 1.2625 - val_mae: 1.2625\n",
            "Epoch 401/1000\n",
            "36/36 - 4s - loss: 1.2583 - mae: 1.2583 - val_loss: 1.0912 - val_mae: 1.0912\n",
            "Epoch 402/1000\n",
            "36/36 - 4s - loss: 1.3098 - mae: 1.3098 - val_loss: 1.2841 - val_mae: 1.2841\n",
            "Epoch 403/1000\n",
            "36/36 - 4s - loss: 1.3185 - mae: 1.3185 - val_loss: 1.1549 - val_mae: 1.1549\n",
            "Epoch 404/1000\n",
            "36/36 - 4s - loss: 1.4258 - mae: 1.4258 - val_loss: 1.4147 - val_mae: 1.4147\n",
            "Epoch 405/1000\n",
            "36/36 - 4s - loss: 1.3691 - mae: 1.3691 - val_loss: 1.3193 - val_mae: 1.3193\n",
            "Epoch 406/1000\n",
            "36/36 - 4s - loss: 1.3117 - mae: 1.3117 - val_loss: 1.1084 - val_mae: 1.1084\n",
            "Epoch 407/1000\n",
            "36/36 - 4s - loss: 1.3520 - mae: 1.3520 - val_loss: 1.2819 - val_mae: 1.2819\n",
            "Epoch 408/1000\n",
            "36/36 - 4s - loss: 1.3746 - mae: 1.3746 - val_loss: 1.3167 - val_mae: 1.3167\n",
            "Epoch 409/1000\n",
            "36/36 - 4s - loss: 1.2981 - mae: 1.2981 - val_loss: 1.2967 - val_mae: 1.2967\n",
            "Epoch 410/1000\n",
            "36/36 - 4s - loss: 1.2784 - mae: 1.2784 - val_loss: 1.1174 - val_mae: 1.1174\n",
            "Epoch 411/1000\n",
            "36/36 - 4s - loss: 1.3510 - mae: 1.3510 - val_loss: 1.2804 - val_mae: 1.2804\n",
            "Epoch 412/1000\n",
            "36/36 - 4s - loss: 1.4052 - mae: 1.4052 - val_loss: 1.1727 - val_mae: 1.1727\n",
            "Epoch 413/1000\n",
            "36/36 - 4s - loss: 1.2773 - mae: 1.2773 - val_loss: 1.0940 - val_mae: 1.0940\n",
            "Epoch 414/1000\n",
            "36/36 - 4s - loss: 1.3381 - mae: 1.3381 - val_loss: 1.2145 - val_mae: 1.2145\n",
            "Epoch 415/1000\n",
            "36/36 - 4s - loss: 1.3557 - mae: 1.3557 - val_loss: 1.3594 - val_mae: 1.3594\n",
            "Epoch 416/1000\n",
            "36/36 - 4s - loss: 1.3076 - mae: 1.3076 - val_loss: 1.2757 - val_mae: 1.2757\n",
            "Epoch 417/1000\n",
            "36/36 - 4s - loss: 1.3328 - mae: 1.3328 - val_loss: 1.0870 - val_mae: 1.0870\n",
            "Epoch 418/1000\n",
            "36/36 - 4s - loss: 1.2793 - mae: 1.2793 - val_loss: 1.1715 - val_mae: 1.1715\n",
            "Epoch 419/1000\n",
            "36/36 - 4s - loss: 1.3952 - mae: 1.3952 - val_loss: 1.2599 - val_mae: 1.2599\n",
            "Epoch 420/1000\n",
            "36/36 - 4s - loss: 1.3182 - mae: 1.3182 - val_loss: 1.2254 - val_mae: 1.2254\n",
            "Epoch 421/1000\n",
            "36/36 - 4s - loss: 1.3189 - mae: 1.3189 - val_loss: 1.3449 - val_mae: 1.3449\n",
            "Epoch 422/1000\n",
            "36/36 - 4s - loss: 1.3490 - mae: 1.3490 - val_loss: 1.2861 - val_mae: 1.2861\n",
            "Epoch 423/1000\n",
            "36/36 - 4s - loss: 1.3448 - mae: 1.3448 - val_loss: 1.3189 - val_mae: 1.3189\n",
            "Epoch 424/1000\n",
            "36/36 - 4s - loss: 1.3698 - mae: 1.3698 - val_loss: 1.1912 - val_mae: 1.1912\n",
            "Epoch 425/1000\n",
            "36/36 - 4s - loss: 1.3707 - mae: 1.3707 - val_loss: 1.2597 - val_mae: 1.2597\n",
            "Epoch 426/1000\n",
            "36/36 - 4s - loss: 1.3670 - mae: 1.3670 - val_loss: 1.1130 - val_mae: 1.1130\n",
            "Epoch 427/1000\n",
            "36/36 - 4s - loss: 1.2942 - mae: 1.2942 - val_loss: 1.1369 - val_mae: 1.1369\n",
            "Epoch 428/1000\n",
            "36/36 - 4s - loss: 1.3264 - mae: 1.3264 - val_loss: 1.1424 - val_mae: 1.1424\n",
            "Epoch 429/1000\n",
            "36/36 - 4s - loss: 1.3415 - mae: 1.3415 - val_loss: 1.1348 - val_mae: 1.1348\n",
            "Epoch 430/1000\n",
            "36/36 - 4s - loss: 1.3607 - mae: 1.3607 - val_loss: 1.1415 - val_mae: 1.1415\n",
            "Epoch 431/1000\n",
            "36/36 - 4s - loss: 1.3379 - mae: 1.3379 - val_loss: 1.1363 - val_mae: 1.1363\n",
            "Epoch 432/1000\n",
            "36/36 - 4s - loss: 1.3285 - mae: 1.3285 - val_loss: 1.1597 - val_mae: 1.1597\n",
            "Epoch 433/1000\n",
            "36/36 - 4s - loss: 1.2560 - mae: 1.2560 - val_loss: 1.1194 - val_mae: 1.1194\n",
            "Epoch 434/1000\n",
            "36/36 - 4s - loss: 1.2264 - mae: 1.2264 - val_loss: 1.1244 - val_mae: 1.1244\n",
            "Epoch 435/1000\n",
            "36/36 - 4s - loss: 1.2601 - mae: 1.2601 - val_loss: 1.1562 - val_mae: 1.1562\n",
            "Epoch 436/1000\n",
            "36/36 - 4s - loss: 1.2408 - mae: 1.2408 - val_loss: 1.0886 - val_mae: 1.0886\n",
            "Epoch 437/1000\n",
            "36/36 - 4s - loss: 1.2895 - mae: 1.2895 - val_loss: 1.1074 - val_mae: 1.1074\n",
            "Epoch 438/1000\n",
            "36/36 - 4s - loss: 1.2774 - mae: 1.2774 - val_loss: 1.1220 - val_mae: 1.1220\n",
            "Epoch 439/1000\n",
            "36/36 - 4s - loss: 1.2620 - mae: 1.2620 - val_loss: 1.2894 - val_mae: 1.2894\n",
            "Epoch 440/1000\n",
            "36/36 - 4s - loss: 1.2574 - mae: 1.2574 - val_loss: 1.1299 - val_mae: 1.1299\n",
            "Epoch 441/1000\n",
            "36/36 - 4s - loss: 1.3541 - mae: 1.3541 - val_loss: 1.2490 - val_mae: 1.2490\n",
            "Epoch 442/1000\n",
            "36/36 - 4s - loss: 1.3048 - mae: 1.3048 - val_loss: 1.2478 - val_mae: 1.2478\n",
            "Epoch 443/1000\n",
            "36/36 - 4s - loss: 1.2779 - mae: 1.2779 - val_loss: 1.1142 - val_mae: 1.1142\n",
            "Epoch 444/1000\n",
            "36/36 - 4s - loss: 1.2607 - mae: 1.2607 - val_loss: 1.0118 - val_mae: 1.0118\n",
            "Epoch 445/1000\n",
            "36/36 - 4s - loss: 1.2916 - mae: 1.2916 - val_loss: 1.1597 - val_mae: 1.1597\n",
            "Epoch 446/1000\n",
            "36/36 - 4s - loss: 1.2566 - mae: 1.2566 - val_loss: 1.1577 - val_mae: 1.1577\n",
            "Epoch 447/1000\n",
            "36/36 - 4s - loss: 1.3174 - mae: 1.3174 - val_loss: 1.1970 - val_mae: 1.1970\n",
            "Epoch 448/1000\n",
            "36/36 - 4s - loss: 1.2745 - mae: 1.2745 - val_loss: 1.1369 - val_mae: 1.1369\n",
            "Epoch 449/1000\n",
            "36/36 - 4s - loss: 1.3128 - mae: 1.3128 - val_loss: 1.1702 - val_mae: 1.1702\n",
            "Epoch 450/1000\n",
            "36/36 - 4s - loss: 1.3661 - mae: 1.3661 - val_loss: 1.1709 - val_mae: 1.1709\n",
            "Epoch 451/1000\n",
            "36/36 - 4s - loss: 1.3737 - mae: 1.3737 - val_loss: 1.0979 - val_mae: 1.0979\n",
            "Epoch 452/1000\n",
            "36/36 - 4s - loss: 1.2500 - mae: 1.2500 - val_loss: 1.1504 - val_mae: 1.1504\n",
            "Epoch 453/1000\n",
            "36/36 - 4s - loss: 1.2172 - mae: 1.2172 - val_loss: 1.1636 - val_mae: 1.1636\n",
            "Epoch 454/1000\n",
            "36/36 - 4s - loss: 1.2918 - mae: 1.2918 - val_loss: 1.1722 - val_mae: 1.1722\n",
            "Epoch 455/1000\n",
            "36/36 - 4s - loss: 1.3188 - mae: 1.3188 - val_loss: 1.1691 - val_mae: 1.1691\n",
            "Epoch 456/1000\n",
            "36/36 - 4s - loss: 1.2649 - mae: 1.2649 - val_loss: 1.3896 - val_mae: 1.3896\n",
            "Epoch 457/1000\n",
            "36/36 - 4s - loss: 1.2942 - mae: 1.2942 - val_loss: 1.2559 - val_mae: 1.2559\n",
            "Epoch 458/1000\n",
            "36/36 - 4s - loss: 1.3020 - mae: 1.3020 - val_loss: 1.1039 - val_mae: 1.1039\n",
            "Epoch 459/1000\n",
            "36/36 - 4s - loss: 1.2804 - mae: 1.2804 - val_loss: 1.1794 - val_mae: 1.1794\n",
            "Epoch 460/1000\n",
            "36/36 - 4s - loss: 1.2201 - mae: 1.2201 - val_loss: 1.0548 - val_mae: 1.0548\n",
            "Epoch 461/1000\n",
            "36/36 - 4s - loss: 1.2725 - mae: 1.2725 - val_loss: 1.0567 - val_mae: 1.0567\n",
            "Epoch 462/1000\n",
            "36/36 - 4s - loss: 1.2546 - mae: 1.2546 - val_loss: 1.0752 - val_mae: 1.0752\n",
            "Epoch 463/1000\n",
            "36/36 - 4s - loss: 1.2798 - mae: 1.2798 - val_loss: 1.2652 - val_mae: 1.2652\n",
            "Epoch 464/1000\n",
            "36/36 - 4s - loss: 1.2471 - mae: 1.2471 - val_loss: 1.1066 - val_mae: 1.1066\n",
            "Epoch 465/1000\n",
            "36/36 - 4s - loss: 1.2286 - mae: 1.2286 - val_loss: 1.1266 - val_mae: 1.1266\n",
            "Epoch 466/1000\n",
            "36/36 - 4s - loss: 1.3000 - mae: 1.3000 - val_loss: 1.2048 - val_mae: 1.2048\n",
            "Epoch 467/1000\n",
            "36/36 - 4s - loss: 1.2541 - mae: 1.2541 - val_loss: 1.0378 - val_mae: 1.0378\n",
            "Epoch 468/1000\n",
            "36/36 - 4s - loss: 1.3299 - mae: 1.3299 - val_loss: 1.1534 - val_mae: 1.1534\n",
            "Epoch 469/1000\n",
            "36/36 - 4s - loss: 1.2922 - mae: 1.2922 - val_loss: 1.1813 - val_mae: 1.1813\n",
            "Epoch 470/1000\n",
            "36/36 - 4s - loss: 1.3325 - mae: 1.3325 - val_loss: 1.1225 - val_mae: 1.1225\n",
            "Epoch 471/1000\n",
            "36/36 - 4s - loss: 1.2289 - mae: 1.2289 - val_loss: 1.2622 - val_mae: 1.2622\n",
            "Epoch 472/1000\n",
            "36/36 - 4s - loss: 1.2411 - mae: 1.2411 - val_loss: 1.1171 - val_mae: 1.1171\n",
            "Epoch 473/1000\n",
            "36/36 - 4s - loss: 1.2167 - mae: 1.2167 - val_loss: 1.2258 - val_mae: 1.2258\n",
            "Epoch 474/1000\n",
            "36/36 - 4s - loss: 1.2884 - mae: 1.2884 - val_loss: 1.1533 - val_mae: 1.1533\n",
            "Epoch 475/1000\n",
            "36/36 - 4s - loss: 1.2647 - mae: 1.2647 - val_loss: 1.1344 - val_mae: 1.1344\n",
            "Epoch 476/1000\n",
            "36/36 - 4s - loss: 1.2827 - mae: 1.2827 - val_loss: 1.0726 - val_mae: 1.0726\n",
            "Epoch 477/1000\n",
            "36/36 - 4s - loss: 1.3468 - mae: 1.3468 - val_loss: 1.2281 - val_mae: 1.2281\n",
            "Epoch 478/1000\n",
            "36/36 - 4s - loss: 1.2115 - mae: 1.2115 - val_loss: 1.1414 - val_mae: 1.1414\n",
            "Epoch 479/1000\n",
            "36/36 - 4s - loss: 1.2754 - mae: 1.2754 - val_loss: 1.1325 - val_mae: 1.1325\n",
            "Epoch 480/1000\n",
            "36/36 - 4s - loss: 1.3064 - mae: 1.3064 - val_loss: 1.1305 - val_mae: 1.1305\n",
            "Epoch 481/1000\n",
            "36/36 - 4s - loss: 1.1549 - mae: 1.1549 - val_loss: 1.0992 - val_mae: 1.0992\n",
            "Epoch 482/1000\n",
            "36/36 - 4s - loss: 1.2307 - mae: 1.2307 - val_loss: 1.1297 - val_mae: 1.1297\n",
            "Epoch 483/1000\n",
            "36/36 - 4s - loss: 1.2399 - mae: 1.2399 - val_loss: 1.1078 - val_mae: 1.1078\n",
            "Epoch 484/1000\n",
            "36/36 - 4s - loss: 1.3764 - mae: 1.3764 - val_loss: 1.1995 - val_mae: 1.1995\n",
            "Epoch 485/1000\n",
            "36/36 - 4s - loss: 1.2321 - mae: 1.2321 - val_loss: 1.0925 - val_mae: 1.0925\n",
            "Epoch 486/1000\n",
            "36/36 - 4s - loss: 1.2871 - mae: 1.2871 - val_loss: 1.3341 - val_mae: 1.3341\n",
            "Epoch 487/1000\n",
            "36/36 - 4s - loss: 1.2817 - mae: 1.2817 - val_loss: 1.0932 - val_mae: 1.0932\n",
            "Epoch 488/1000\n",
            "36/36 - 4s - loss: 1.1880 - mae: 1.1880 - val_loss: 1.0506 - val_mae: 1.0506\n",
            "Epoch 489/1000\n",
            "36/36 - 4s - loss: 1.2138 - mae: 1.2138 - val_loss: 1.1832 - val_mae: 1.1832\n",
            "Epoch 490/1000\n",
            "36/36 - 4s - loss: 1.2829 - mae: 1.2829 - val_loss: 1.1457 - val_mae: 1.1457\n",
            "Epoch 491/1000\n",
            "36/36 - 4s - loss: 1.2683 - mae: 1.2683 - val_loss: 1.2436 - val_mae: 1.2436\n",
            "Epoch 492/1000\n",
            "36/36 - 4s - loss: 1.2054 - mae: 1.2054 - val_loss: 1.0924 - val_mae: 1.0924\n",
            "Epoch 493/1000\n",
            "36/36 - 4s - loss: 1.3399 - mae: 1.3399 - val_loss: 1.1370 - val_mae: 1.1370\n",
            "Epoch 494/1000\n",
            "36/36 - 4s - loss: 1.3030 - mae: 1.3030 - val_loss: 1.0447 - val_mae: 1.0447\n",
            "Epoch 495/1000\n",
            "36/36 - 4s - loss: 1.1954 - mae: 1.1954 - val_loss: 1.1230 - val_mae: 1.1230\n",
            "Epoch 496/1000\n",
            "36/36 - 4s - loss: 1.2724 - mae: 1.2724 - val_loss: 1.0459 - val_mae: 1.0459\n",
            "Epoch 497/1000\n",
            "36/36 - 4s - loss: 1.1957 - mae: 1.1957 - val_loss: 1.1310 - val_mae: 1.1310\n",
            "Epoch 498/1000\n",
            "36/36 - 4s - loss: 1.2154 - mae: 1.2154 - val_loss: 0.9548 - val_mae: 0.9548\n",
            "Epoch 499/1000\n",
            "36/36 - 4s - loss: 1.2166 - mae: 1.2166 - val_loss: 1.1832 - val_mae: 1.1832\n",
            "Epoch 500/1000\n",
            "36/36 - 4s - loss: 1.2448 - mae: 1.2448 - val_loss: 1.1704 - val_mae: 1.1704\n",
            "Epoch 501/1000\n",
            "36/36 - 4s - loss: 1.1750 - mae: 1.1750 - val_loss: 1.0253 - val_mae: 1.0253\n",
            "Epoch 502/1000\n",
            "36/36 - 4s - loss: 1.1368 - mae: 1.1368 - val_loss: 1.0782 - val_mae: 1.0782\n",
            "Epoch 503/1000\n",
            "36/36 - 4s - loss: 1.2445 - mae: 1.2445 - val_loss: 1.0642 - val_mae: 1.0642\n",
            "Epoch 504/1000\n",
            "36/36 - 4s - loss: 1.2859 - mae: 1.2859 - val_loss: 1.1126 - val_mae: 1.1126\n",
            "Epoch 505/1000\n",
            "36/36 - 4s - loss: 1.2590 - mae: 1.2590 - val_loss: 1.1047 - val_mae: 1.1047\n",
            "Epoch 506/1000\n",
            "36/36 - 4s - loss: 1.2735 - mae: 1.2735 - val_loss: 1.0452 - val_mae: 1.0452\n",
            "Epoch 507/1000\n",
            "36/36 - 4s - loss: 1.3115 - mae: 1.3115 - val_loss: 1.1197 - val_mae: 1.1197\n",
            "Epoch 508/1000\n",
            "36/36 - 4s - loss: 1.1875 - mae: 1.1875 - val_loss: 1.0836 - val_mae: 1.0836\n",
            "Epoch 509/1000\n",
            "36/36 - 4s - loss: 1.2307 - mae: 1.2307 - val_loss: 1.0177 - val_mae: 1.0177\n",
            "Epoch 510/1000\n",
            "36/36 - 4s - loss: 1.1964 - mae: 1.1964 - val_loss: 1.1106 - val_mae: 1.1106\n",
            "Epoch 511/1000\n",
            "36/36 - 4s - loss: 1.2025 - mae: 1.2025 - val_loss: 1.0880 - val_mae: 1.0880\n",
            "Epoch 512/1000\n",
            "36/36 - 4s - loss: 1.2931 - mae: 1.2931 - val_loss: 1.0743 - val_mae: 1.0743\n",
            "Epoch 513/1000\n",
            "36/36 - 4s - loss: 1.1845 - mae: 1.1845 - val_loss: 0.9944 - val_mae: 0.9944\n",
            "Epoch 514/1000\n",
            "36/36 - 4s - loss: 1.2663 - mae: 1.2663 - val_loss: 1.1549 - val_mae: 1.1549\n",
            "Epoch 515/1000\n",
            "36/36 - 4s - loss: 1.2923 - mae: 1.2923 - val_loss: 1.1325 - val_mae: 1.1325\n",
            "Epoch 516/1000\n",
            "36/36 - 4s - loss: 1.1823 - mae: 1.1823 - val_loss: 1.0810 - val_mae: 1.0810\n",
            "Epoch 517/1000\n",
            "36/36 - 4s - loss: 1.2121 - mae: 1.2121 - val_loss: 1.0983 - val_mae: 1.0983\n",
            "Epoch 518/1000\n",
            "36/36 - 4s - loss: 1.2208 - mae: 1.2208 - val_loss: 1.2319 - val_mae: 1.2319\n",
            "Epoch 519/1000\n",
            "36/36 - 4s - loss: 1.2293 - mae: 1.2293 - val_loss: 1.0352 - val_mae: 1.0352\n",
            "Epoch 520/1000\n",
            "36/36 - 4s - loss: 1.2881 - mae: 1.2881 - val_loss: 1.1105 - val_mae: 1.1105\n",
            "Epoch 521/1000\n",
            "36/36 - 4s - loss: 1.2500 - mae: 1.2500 - val_loss: 1.0294 - val_mae: 1.0294\n",
            "Epoch 522/1000\n",
            "36/36 - 4s - loss: 1.1879 - mae: 1.1879 - val_loss: 1.0275 - val_mae: 1.0275\n",
            "Epoch 523/1000\n",
            "36/36 - 4s - loss: 1.2250 - mae: 1.2250 - val_loss: 1.0538 - val_mae: 1.0538\n",
            "Epoch 524/1000\n",
            "36/36 - 4s - loss: 1.2301 - mae: 1.2301 - val_loss: 1.0902 - val_mae: 1.0902\n",
            "Epoch 525/1000\n",
            "36/36 - 4s - loss: 1.3485 - mae: 1.3485 - val_loss: 1.1581 - val_mae: 1.1581\n",
            "Epoch 526/1000\n",
            "36/36 - 4s - loss: 1.2387 - mae: 1.2387 - val_loss: 1.1110 - val_mae: 1.1110\n",
            "Epoch 527/1000\n",
            "36/36 - 4s - loss: 1.1558 - mae: 1.1558 - val_loss: 1.0034 - val_mae: 1.0034\n",
            "Epoch 528/1000\n",
            "36/36 - 4s - loss: 1.1847 - mae: 1.1847 - val_loss: 1.0190 - val_mae: 1.0190\n",
            "Epoch 529/1000\n",
            "36/36 - 4s - loss: 1.1757 - mae: 1.1757 - val_loss: 1.0799 - val_mae: 1.0799\n",
            "Epoch 530/1000\n",
            "36/36 - 4s - loss: 1.2585 - mae: 1.2585 - val_loss: 1.2184 - val_mae: 1.2184\n",
            "Epoch 531/1000\n",
            "36/36 - 4s - loss: 1.2476 - mae: 1.2476 - val_loss: 1.0527 - val_mae: 1.0527\n",
            "Epoch 532/1000\n",
            "36/36 - 4s - loss: 1.2259 - mae: 1.2259 - val_loss: 1.1527 - val_mae: 1.1527\n",
            "Epoch 533/1000\n",
            "36/36 - 4s - loss: 1.2614 - mae: 1.2614 - val_loss: 1.1115 - val_mae: 1.1115\n",
            "Epoch 534/1000\n",
            "36/36 - 4s - loss: 1.2328 - mae: 1.2328 - val_loss: 1.0317 - val_mae: 1.0317\n",
            "Epoch 535/1000\n",
            "36/36 - 4s - loss: 1.1649 - mae: 1.1649 - val_loss: 1.0449 - val_mae: 1.0449\n",
            "Epoch 536/1000\n",
            "36/36 - 4s - loss: 1.2547 - mae: 1.2547 - val_loss: 1.0719 - val_mae: 1.0719\n",
            "Epoch 537/1000\n",
            "36/36 - 4s - loss: 1.1962 - mae: 1.1962 - val_loss: 1.0041 - val_mae: 1.0041\n",
            "Epoch 538/1000\n",
            "36/36 - 4s - loss: 1.1682 - mae: 1.1682 - val_loss: 1.0126 - val_mae: 1.0126\n",
            "Epoch 539/1000\n",
            "36/36 - 4s - loss: 1.2223 - mae: 1.2223 - val_loss: 1.2137 - val_mae: 1.2137\n",
            "Epoch 540/1000\n",
            "36/36 - 4s - loss: 1.3221 - mae: 1.3221 - val_loss: 1.1223 - val_mae: 1.1223\n",
            "Epoch 541/1000\n",
            "36/36 - 4s - loss: 1.2878 - mae: 1.2878 - val_loss: 1.2544 - val_mae: 1.2544\n",
            "Epoch 542/1000\n",
            "36/36 - 4s - loss: 1.2147 - mae: 1.2147 - val_loss: 1.1194 - val_mae: 1.1194\n",
            "Epoch 543/1000\n",
            "36/36 - 4s - loss: 1.2348 - mae: 1.2348 - val_loss: 1.1553 - val_mae: 1.1553\n",
            "Epoch 544/1000\n",
            "36/36 - 4s - loss: 1.2332 - mae: 1.2332 - val_loss: 1.0968 - val_mae: 1.0968\n",
            "Epoch 545/1000\n",
            "36/36 - 4s - loss: 1.1618 - mae: 1.1618 - val_loss: 1.0226 - val_mae: 1.0226\n",
            "Epoch 546/1000\n",
            "36/36 - 4s - loss: 1.2223 - mae: 1.2223 - val_loss: 1.0294 - val_mae: 1.0294\n",
            "Epoch 547/1000\n",
            "36/36 - 4s - loss: 1.1743 - mae: 1.1743 - val_loss: 1.2007 - val_mae: 1.2007\n",
            "Epoch 548/1000\n",
            "36/36 - 4s - loss: 1.1684 - mae: 1.1684 - val_loss: 1.0692 - val_mae: 1.0692\n",
            "Epoch 549/1000\n",
            "36/36 - 4s - loss: 1.2508 - mae: 1.2508 - val_loss: 1.0169 - val_mae: 1.0169\n",
            "Epoch 550/1000\n",
            "36/36 - 4s - loss: 1.2048 - mae: 1.2048 - val_loss: 1.0786 - val_mae: 1.0786\n",
            "Epoch 551/1000\n",
            "36/36 - 4s - loss: 1.2225 - mae: 1.2225 - val_loss: 1.1247 - val_mae: 1.1247\n",
            "Epoch 552/1000\n",
            "36/36 - 4s - loss: 1.2464 - mae: 1.2464 - val_loss: 1.1643 - val_mae: 1.1643\n",
            "Epoch 553/1000\n",
            "36/36 - 4s - loss: 1.2314 - mae: 1.2314 - val_loss: 1.1029 - val_mae: 1.1029\n",
            "Epoch 554/1000\n",
            "36/36 - 4s - loss: 1.1841 - mae: 1.1841 - val_loss: 1.1773 - val_mae: 1.1773\n",
            "Epoch 555/1000\n",
            "36/36 - 4s - loss: 1.1811 - mae: 1.1811 - val_loss: 0.9921 - val_mae: 0.9921\n",
            "Epoch 556/1000\n",
            "36/36 - 4s - loss: 1.2112 - mae: 1.2112 - val_loss: 1.0526 - val_mae: 1.0526\n",
            "Epoch 557/1000\n",
            "36/36 - 4s - loss: 1.1584 - mae: 1.1584 - val_loss: 1.1146 - val_mae: 1.1146\n",
            "Epoch 558/1000\n",
            "36/36 - 4s - loss: 1.2752 - mae: 1.2752 - val_loss: 0.9812 - val_mae: 0.9812\n",
            "Epoch 559/1000\n",
            "36/36 - 4s - loss: 1.2453 - mae: 1.2453 - val_loss: 1.0469 - val_mae: 1.0469\n",
            "Epoch 560/1000\n",
            "36/36 - 4s - loss: 1.1417 - mae: 1.1417 - val_loss: 0.9801 - val_mae: 0.9801\n",
            "Epoch 561/1000\n",
            "36/36 - 4s - loss: 1.1575 - mae: 1.1575 - val_loss: 1.0573 - val_mae: 1.0573\n",
            "Epoch 562/1000\n",
            "36/36 - 4s - loss: 1.1628 - mae: 1.1628 - val_loss: 0.9934 - val_mae: 0.9934\n",
            "Epoch 563/1000\n",
            "36/36 - 4s - loss: 1.1660 - mae: 1.1660 - val_loss: 1.0339 - val_mae: 1.0339\n",
            "Epoch 564/1000\n",
            "36/36 - 4s - loss: 1.1484 - mae: 1.1484 - val_loss: 0.9979 - val_mae: 0.9979\n",
            "Epoch 565/1000\n",
            "36/36 - 4s - loss: 1.1108 - mae: 1.1108 - val_loss: 0.9845 - val_mae: 0.9845\n",
            "Epoch 566/1000\n",
            "36/36 - 4s - loss: 1.2093 - mae: 1.2093 - val_loss: 1.1478 - val_mae: 1.1478\n",
            "Epoch 567/1000\n",
            "36/36 - 4s - loss: 1.2956 - mae: 1.2956 - val_loss: 1.1015 - val_mae: 1.1015\n",
            "Epoch 568/1000\n",
            "36/36 - 4s - loss: 1.2046 - mae: 1.2046 - val_loss: 1.1044 - val_mae: 1.1044\n",
            "Epoch 569/1000\n",
            "36/36 - 4s - loss: 1.1854 - mae: 1.1854 - val_loss: 0.9755 - val_mae: 0.9755\n",
            "Epoch 570/1000\n",
            "36/36 - 4s - loss: 1.1832 - mae: 1.1832 - val_loss: 1.1506 - val_mae: 1.1506\n",
            "Epoch 571/1000\n",
            "36/36 - 4s - loss: 1.0986 - mae: 1.0986 - val_loss: 0.9975 - val_mae: 0.9975\n",
            "Epoch 572/1000\n",
            "36/36 - 4s - loss: 1.1644 - mae: 1.1644 - val_loss: 1.0301 - val_mae: 1.0301\n",
            "Epoch 573/1000\n",
            "36/36 - 4s - loss: 1.2013 - mae: 1.2013 - val_loss: 1.0750 - val_mae: 1.0750\n",
            "Epoch 574/1000\n",
            "36/36 - 4s - loss: 1.1383 - mae: 1.1383 - val_loss: 1.0087 - val_mae: 1.0087\n",
            "Epoch 575/1000\n",
            "36/36 - 4s - loss: 1.2007 - mae: 1.2007 - val_loss: 1.1593 - val_mae: 1.1593\n",
            "Epoch 576/1000\n",
            "36/36 - 4s - loss: 1.2260 - mae: 1.2260 - val_loss: 1.2148 - val_mae: 1.2148\n",
            "Epoch 577/1000\n",
            "36/36 - 4s - loss: 1.2497 - mae: 1.2497 - val_loss: 1.0561 - val_mae: 1.0561\n",
            "Epoch 578/1000\n",
            "36/36 - 4s - loss: 1.1484 - mae: 1.1484 - val_loss: 1.0289 - val_mae: 1.0289\n",
            "Epoch 579/1000\n",
            "36/36 - 4s - loss: 1.1463 - mae: 1.1463 - val_loss: 1.0425 - val_mae: 1.0425\n",
            "Epoch 580/1000\n",
            "36/36 - 4s - loss: 1.1539 - mae: 1.1539 - val_loss: 1.0672 - val_mae: 1.0672\n",
            "Epoch 581/1000\n",
            "36/36 - 4s - loss: 1.1736 - mae: 1.1736 - val_loss: 1.0197 - val_mae: 1.0197\n",
            "Epoch 582/1000\n",
            "36/36 - 4s - loss: 1.2030 - mae: 1.2030 - val_loss: 1.0115 - val_mae: 1.0115\n",
            "Epoch 583/1000\n",
            "36/36 - 4s - loss: 1.2318 - mae: 1.2318 - val_loss: 0.9660 - val_mae: 0.9660\n",
            "Epoch 584/1000\n",
            "36/36 - 4s - loss: 1.2078 - mae: 1.2078 - val_loss: 1.0346 - val_mae: 1.0346\n",
            "Epoch 585/1000\n",
            "36/36 - 4s - loss: 1.2321 - mae: 1.2321 - val_loss: 1.1799 - val_mae: 1.1799\n",
            "Epoch 586/1000\n",
            "36/36 - 4s - loss: 1.1536 - mae: 1.1536 - val_loss: 0.9742 - val_mae: 0.9742\n",
            "Epoch 587/1000\n",
            "36/36 - 4s - loss: 1.0554 - mae: 1.0554 - val_loss: 0.9893 - val_mae: 0.9893\n",
            "Epoch 588/1000\n",
            "36/36 - 4s - loss: 1.2572 - mae: 1.2572 - val_loss: 1.0059 - val_mae: 1.0059\n",
            "Epoch 589/1000\n",
            "36/36 - 4s - loss: 1.1108 - mae: 1.1108 - val_loss: 1.0344 - val_mae: 1.0344\n",
            "Epoch 590/1000\n",
            "36/36 - 4s - loss: 1.2122 - mae: 1.2122 - val_loss: 0.9963 - val_mae: 0.9963\n",
            "Epoch 591/1000\n",
            "36/36 - 4s - loss: 1.1091 - mae: 1.1091 - val_loss: 0.9812 - val_mae: 0.9812\n",
            "Epoch 592/1000\n",
            "36/36 - 4s - loss: 1.1508 - mae: 1.1508 - val_loss: 1.0986 - val_mae: 1.0986\n",
            "Epoch 593/1000\n",
            "36/36 - 4s - loss: 1.1769 - mae: 1.1769 - val_loss: 1.0444 - val_mae: 1.0444\n",
            "Epoch 594/1000\n",
            "36/36 - 4s - loss: 1.1098 - mae: 1.1098 - val_loss: 1.0297 - val_mae: 1.0297\n",
            "Epoch 595/1000\n",
            "36/36 - 4s - loss: 1.1949 - mae: 1.1949 - val_loss: 1.0919 - val_mae: 1.0919\n",
            "Epoch 596/1000\n",
            "36/36 - 4s - loss: 1.0925 - mae: 1.0925 - val_loss: 1.1378 - val_mae: 1.1378\n",
            "Epoch 597/1000\n",
            "36/36 - 4s - loss: 1.1421 - mae: 1.1421 - val_loss: 0.9783 - val_mae: 0.9783\n",
            "Epoch 598/1000\n",
            "36/36 - 4s - loss: 1.0901 - mae: 1.0901 - val_loss: 0.9375 - val_mae: 0.9375\n",
            "Epoch 599/1000\n",
            "36/36 - 4s - loss: 1.0803 - mae: 1.0803 - val_loss: 0.9516 - val_mae: 0.9516\n",
            "Epoch 600/1000\n",
            "36/36 - 4s - loss: 1.1255 - mae: 1.1255 - val_loss: 0.9932 - val_mae: 0.9932\n",
            "Epoch 601/1000\n",
            "36/36 - 4s - loss: 1.1576 - mae: 1.1576 - val_loss: 1.0032 - val_mae: 1.0032\n",
            "Epoch 602/1000\n",
            "36/36 - 4s - loss: 1.1294 - mae: 1.1294 - val_loss: 1.0441 - val_mae: 1.0441\n",
            "Epoch 603/1000\n",
            "36/36 - 4s - loss: 1.2084 - mae: 1.2084 - val_loss: 1.0145 - val_mae: 1.0145\n",
            "Epoch 604/1000\n",
            "36/36 - 4s - loss: 1.1521 - mae: 1.1521 - val_loss: 0.9635 - val_mae: 0.9635\n",
            "Epoch 605/1000\n",
            "36/36 - 4s - loss: 1.1086 - mae: 1.1086 - val_loss: 0.9990 - val_mae: 0.9990\n",
            "Epoch 606/1000\n",
            "36/36 - 4s - loss: 1.1802 - mae: 1.1802 - val_loss: 1.0553 - val_mae: 1.0553\n",
            "Epoch 607/1000\n",
            "36/36 - 4s - loss: 1.0918 - mae: 1.0918 - val_loss: 0.9618 - val_mae: 0.9618\n",
            "Epoch 608/1000\n",
            "36/36 - 4s - loss: 1.0817 - mae: 1.0817 - val_loss: 0.8773 - val_mae: 0.8773\n",
            "Epoch 609/1000\n",
            "36/36 - 4s - loss: 1.1331 - mae: 1.1331 - val_loss: 1.0296 - val_mae: 1.0296\n",
            "Epoch 610/1000\n",
            "36/36 - 4s - loss: 1.0971 - mae: 1.0971 - val_loss: 0.9196 - val_mae: 0.9196\n",
            "Epoch 611/1000\n",
            "36/36 - 4s - loss: 1.0618 - mae: 1.0618 - val_loss: 1.0125 - val_mae: 1.0125\n",
            "Epoch 612/1000\n",
            "36/36 - 4s - loss: 1.0344 - mae: 1.0344 - val_loss: 1.1401 - val_mae: 1.1401\n",
            "Epoch 613/1000\n",
            "36/36 - 4s - loss: 1.2874 - mae: 1.2874 - val_loss: 1.1667 - val_mae: 1.1667\n",
            "Epoch 614/1000\n",
            "36/36 - 4s - loss: 1.1998 - mae: 1.1998 - val_loss: 0.9727 - val_mae: 0.9727\n",
            "Epoch 615/1000\n",
            "36/36 - 4s - loss: 1.1796 - mae: 1.1796 - val_loss: 0.9696 - val_mae: 0.9696\n",
            "Epoch 616/1000\n",
            "36/36 - 4s - loss: 1.1141 - mae: 1.1141 - val_loss: 1.0496 - val_mae: 1.0496\n",
            "Epoch 617/1000\n",
            "36/36 - 4s - loss: 1.1174 - mae: 1.1174 - val_loss: 1.0974 - val_mae: 1.0974\n",
            "Epoch 618/1000\n",
            "36/36 - 4s - loss: 1.1039 - mae: 1.1039 - val_loss: 1.0326 - val_mae: 1.0326\n",
            "Epoch 619/1000\n",
            "36/36 - 4s - loss: 1.1387 - mae: 1.1387 - val_loss: 1.0347 - val_mae: 1.0347\n",
            "Epoch 620/1000\n",
            "36/36 - 4s - loss: 1.1487 - mae: 1.1487 - val_loss: 1.0331 - val_mae: 1.0331\n",
            "Epoch 621/1000\n",
            "36/36 - 4s - loss: 1.0959 - mae: 1.0959 - val_loss: 1.0501 - val_mae: 1.0501\n",
            "Epoch 622/1000\n",
            "36/36 - 4s - loss: 1.0968 - mae: 1.0968 - val_loss: 1.0818 - val_mae: 1.0818\n",
            "Epoch 623/1000\n",
            "36/36 - 4s - loss: 1.1264 - mae: 1.1264 - val_loss: 1.0498 - val_mae: 1.0498\n",
            "Epoch 624/1000\n",
            "36/36 - 4s - loss: 1.1091 - mae: 1.1091 - val_loss: 1.0308 - val_mae: 1.0308\n",
            "Epoch 625/1000\n",
            "36/36 - 4s - loss: 1.1240 - mae: 1.1240 - val_loss: 1.0116 - val_mae: 1.0116\n",
            "Epoch 626/1000\n",
            "36/36 - 4s - loss: 1.1635 - mae: 1.1635 - val_loss: 0.9936 - val_mae: 0.9936\n",
            "Epoch 627/1000\n",
            "36/36 - 4s - loss: 1.1528 - mae: 1.1528 - val_loss: 1.0613 - val_mae: 1.0613\n",
            "Epoch 628/1000\n",
            "36/36 - 4s - loss: 1.0802 - mae: 1.0802 - val_loss: 0.9333 - val_mae: 0.9333\n",
            "Epoch 629/1000\n",
            "36/36 - 4s - loss: 1.1334 - mae: 1.1334 - val_loss: 1.0355 - val_mae: 1.0355\n",
            "Epoch 630/1000\n",
            "36/36 - 4s - loss: 1.0882 - mae: 1.0882 - val_loss: 1.0006 - val_mae: 1.0006\n",
            "Epoch 631/1000\n",
            "36/36 - 4s - loss: 1.0967 - mae: 1.0967 - val_loss: 0.9663 - val_mae: 0.9663\n",
            "Epoch 632/1000\n",
            "36/36 - 4s - loss: 1.1223 - mae: 1.1223 - val_loss: 0.9389 - val_mae: 0.9389\n",
            "Epoch 633/1000\n",
            "36/36 - 4s - loss: 1.1185 - mae: 1.1185 - val_loss: 1.0185 - val_mae: 1.0185\n",
            "Epoch 634/1000\n",
            "36/36 - 4s - loss: 1.0824 - mae: 1.0824 - val_loss: 0.8903 - val_mae: 0.8903\n",
            "Epoch 635/1000\n",
            "36/36 - 4s - loss: 1.1385 - mae: 1.1385 - val_loss: 1.1579 - val_mae: 1.1579\n",
            "Epoch 636/1000\n",
            "36/36 - 4s - loss: 1.1618 - mae: 1.1618 - val_loss: 0.9514 - val_mae: 0.9514\n",
            "Epoch 637/1000\n",
            "36/36 - 4s - loss: 1.1433 - mae: 1.1433 - val_loss: 1.0001 - val_mae: 1.0001\n",
            "Epoch 638/1000\n",
            "36/36 - 4s - loss: 1.0828 - mae: 1.0828 - val_loss: 1.0984 - val_mae: 1.0984\n",
            "Epoch 639/1000\n",
            "36/36 - 4s - loss: 1.1748 - mae: 1.1748 - val_loss: 0.9987 - val_mae: 0.9987\n",
            "Epoch 640/1000\n",
            "36/36 - 4s - loss: 1.1264 - mae: 1.1264 - val_loss: 1.0206 - val_mae: 1.0206\n",
            "Epoch 641/1000\n",
            "36/36 - 4s - loss: 1.0523 - mae: 1.0523 - val_loss: 1.0483 - val_mae: 1.0483\n",
            "Epoch 642/1000\n",
            "36/36 - 4s - loss: 1.0971 - mae: 1.0971 - val_loss: 1.0242 - val_mae: 1.0242\n",
            "Epoch 643/1000\n",
            "36/36 - 4s - loss: 1.1578 - mae: 1.1578 - val_loss: 1.0878 - val_mae: 1.0878\n",
            "Epoch 644/1000\n",
            "36/36 - 4s - loss: 1.0986 - mae: 1.0986 - val_loss: 0.9333 - val_mae: 0.9333\n",
            "Epoch 645/1000\n",
            "36/36 - 4s - loss: 1.1141 - mae: 1.1141 - val_loss: 0.9197 - val_mae: 0.9197\n",
            "Epoch 646/1000\n",
            "36/36 - 4s - loss: 1.0789 - mae: 1.0789 - val_loss: 0.8787 - val_mae: 0.8787\n",
            "Epoch 647/1000\n",
            "36/36 - 4s - loss: 1.0918 - mae: 1.0918 - val_loss: 1.0039 - val_mae: 1.0039\n",
            "Epoch 648/1000\n",
            "36/36 - 4s - loss: 1.1348 - mae: 1.1348 - val_loss: 0.9680 - val_mae: 0.9680\n",
            "Epoch 649/1000\n",
            "36/36 - 4s - loss: 1.1932 - mae: 1.1932 - val_loss: 1.0711 - val_mae: 1.0711\n",
            "Epoch 650/1000\n",
            "36/36 - 4s - loss: 1.1398 - mae: 1.1398 - val_loss: 1.0130 - val_mae: 1.0130\n",
            "Epoch 651/1000\n",
            "36/36 - 4s - loss: 1.1692 - mae: 1.1692 - val_loss: 1.0433 - val_mae: 1.0433\n",
            "Epoch 652/1000\n",
            "36/36 - 4s - loss: 1.0972 - mae: 1.0972 - val_loss: 0.9582 - val_mae: 0.9582\n",
            "Epoch 653/1000\n",
            "36/36 - 4s - loss: 1.0912 - mae: 1.0912 - val_loss: 1.0568 - val_mae: 1.0568\n",
            "Epoch 654/1000\n",
            "36/36 - 4s - loss: 1.1542 - mae: 1.1542 - val_loss: 1.0570 - val_mae: 1.0570\n",
            "Epoch 655/1000\n",
            "36/36 - 4s - loss: 1.0020 - mae: 1.0020 - val_loss: 0.9599 - val_mae: 0.9599\n",
            "Epoch 656/1000\n",
            "36/36 - 4s - loss: 1.1373 - mae: 1.1373 - val_loss: 0.9601 - val_mae: 0.9601\n",
            "Epoch 657/1000\n",
            "36/36 - 4s - loss: 1.1014 - mae: 1.1014 - val_loss: 1.0611 - val_mae: 1.0611\n",
            "Epoch 658/1000\n",
            "36/36 - 4s - loss: 1.0815 - mae: 1.0815 - val_loss: 0.8397 - val_mae: 0.8397\n",
            "Epoch 659/1000\n",
            "36/36 - 4s - loss: 1.0455 - mae: 1.0455 - val_loss: 0.9621 - val_mae: 0.9621\n",
            "Epoch 660/1000\n",
            "36/36 - 4s - loss: 1.0891 - mae: 1.0891 - val_loss: 0.9492 - val_mae: 0.9492\n",
            "Epoch 661/1000\n",
            "36/36 - 4s - loss: 1.1311 - mae: 1.1311 - val_loss: 1.1232 - val_mae: 1.1232\n",
            "Epoch 662/1000\n",
            "36/36 - 4s - loss: 1.1703 - mae: 1.1703 - val_loss: 0.9944 - val_mae: 0.9944\n",
            "Epoch 663/1000\n",
            "36/36 - 4s - loss: 1.0994 - mae: 1.0994 - val_loss: 0.9398 - val_mae: 0.9398\n",
            "Epoch 664/1000\n",
            "36/36 - 4s - loss: 1.0919 - mae: 1.0919 - val_loss: 0.9945 - val_mae: 0.9945\n",
            "Epoch 665/1000\n",
            "36/36 - 4s - loss: 1.0967 - mae: 1.0967 - val_loss: 1.0863 - val_mae: 1.0863\n",
            "Epoch 666/1000\n",
            "36/36 - 4s - loss: 1.0336 - mae: 1.0336 - val_loss: 0.9216 - val_mae: 0.9216\n",
            "Epoch 667/1000\n",
            "36/36 - 4s - loss: 1.1349 - mae: 1.1349 - val_loss: 1.0605 - val_mae: 1.0605\n",
            "Epoch 668/1000\n",
            "36/36 - 4s - loss: 1.1961 - mae: 1.1961 - val_loss: 0.9342 - val_mae: 0.9342\n",
            "Epoch 669/1000\n",
            "36/36 - 4s - loss: 1.1893 - mae: 1.1893 - val_loss: 1.1367 - val_mae: 1.1367\n",
            "Epoch 670/1000\n",
            "36/36 - 4s - loss: 1.0663 - mae: 1.0663 - val_loss: 1.0708 - val_mae: 1.0708\n",
            "Epoch 671/1000\n",
            "36/36 - 4s - loss: 1.1657 - mae: 1.1657 - val_loss: 1.1267 - val_mae: 1.1267\n",
            "Epoch 672/1000\n",
            "36/36 - 4s - loss: 1.0743 - mae: 1.0743 - val_loss: 1.0083 - val_mae: 1.0083\n",
            "Epoch 673/1000\n",
            "36/36 - 4s - loss: 1.1144 - mae: 1.1144 - val_loss: 0.9757 - val_mae: 0.9757\n",
            "Epoch 674/1000\n",
            "36/36 - 4s - loss: 1.1122 - mae: 1.1122 - val_loss: 0.9206 - val_mae: 0.9206\n",
            "Epoch 675/1000\n",
            "36/36 - 4s - loss: 1.0250 - mae: 1.0250 - val_loss: 0.9790 - val_mae: 0.9790\n",
            "Epoch 676/1000\n",
            "36/36 - 4s - loss: 1.2106 - mae: 1.2106 - val_loss: 0.9988 - val_mae: 0.9988\n",
            "Epoch 677/1000\n",
            "36/36 - 4s - loss: 1.0920 - mae: 1.0920 - val_loss: 1.1405 - val_mae: 1.1405\n",
            "Epoch 678/1000\n",
            "36/36 - 4s - loss: 1.0713 - mae: 1.0713 - val_loss: 0.9680 - val_mae: 0.9680\n",
            "Epoch 679/1000\n",
            "36/36 - 4s - loss: 1.1133 - mae: 1.1133 - val_loss: 0.9487 - val_mae: 0.9487\n",
            "Epoch 680/1000\n",
            "36/36 - 4s - loss: 1.0545 - mae: 1.0545 - val_loss: 0.8836 - val_mae: 0.8836\n",
            "Epoch 681/1000\n",
            "36/36 - 4s - loss: 1.0847 - mae: 1.0847 - val_loss: 0.8660 - val_mae: 0.8660\n",
            "Epoch 682/1000\n",
            "36/36 - 4s - loss: 1.1275 - mae: 1.1275 - val_loss: 0.9063 - val_mae: 0.9063\n",
            "Epoch 683/1000\n",
            "36/36 - 4s - loss: 1.2041 - mae: 1.2041 - val_loss: 1.1139 - val_mae: 1.1139\n",
            "Epoch 684/1000\n",
            "36/36 - 4s - loss: 1.0577 - mae: 1.0577 - val_loss: 0.9919 - val_mae: 0.9919\n",
            "Epoch 685/1000\n",
            "36/36 - 4s - loss: 1.0956 - mae: 1.0956 - val_loss: 0.9773 - val_mae: 0.9773\n",
            "Epoch 686/1000\n",
            "36/36 - 4s - loss: 1.0671 - mae: 1.0671 - val_loss: 0.9678 - val_mae: 0.9678\n",
            "Epoch 687/1000\n",
            "36/36 - 4s - loss: 1.0427 - mae: 1.0427 - val_loss: 0.9755 - val_mae: 0.9755\n",
            "Epoch 688/1000\n",
            "36/36 - 4s - loss: 1.0953 - mae: 1.0953 - val_loss: 0.9397 - val_mae: 0.9397\n",
            "Epoch 689/1000\n",
            "36/36 - 4s - loss: 1.0811 - mae: 1.0811 - val_loss: 0.9386 - val_mae: 0.9386\n",
            "Epoch 690/1000\n",
            "36/36 - 4s - loss: 1.0969 - mae: 1.0969 - val_loss: 0.9101 - val_mae: 0.9101\n",
            "Epoch 691/1000\n",
            "36/36 - 4s - loss: 1.1232 - mae: 1.1232 - val_loss: 0.8503 - val_mae: 0.8503\n",
            "Epoch 692/1000\n",
            "36/36 - 4s - loss: 1.0823 - mae: 1.0823 - val_loss: 0.9163 - val_mae: 0.9163\n",
            "Epoch 693/1000\n",
            "36/36 - 4s - loss: 1.0467 - mae: 1.0467 - val_loss: 0.9271 - val_mae: 0.9271\n",
            "Epoch 694/1000\n",
            "36/36 - 4s - loss: 1.0710 - mae: 1.0710 - val_loss: 1.0474 - val_mae: 1.0474\n",
            "Epoch 695/1000\n",
            "36/36 - 4s - loss: 1.0837 - mae: 1.0837 - val_loss: 0.9587 - val_mae: 0.9587\n",
            "Epoch 696/1000\n",
            "36/36 - 4s - loss: 1.0940 - mae: 1.0940 - val_loss: 0.9164 - val_mae: 0.9164\n",
            "Epoch 697/1000\n",
            "36/36 - 4s - loss: 1.0169 - mae: 1.0169 - val_loss: 0.8832 - val_mae: 0.8832\n",
            "Epoch 698/1000\n",
            "36/36 - 4s - loss: 1.0809 - mae: 1.0809 - val_loss: 0.9572 - val_mae: 0.9572\n",
            "Epoch 699/1000\n",
            "36/36 - 4s - loss: 1.0388 - mae: 1.0388 - val_loss: 0.9438 - val_mae: 0.9438\n",
            "Epoch 700/1000\n",
            "36/36 - 4s - loss: 1.0340 - mae: 1.0340 - val_loss: 0.9250 - val_mae: 0.9250\n",
            "Epoch 701/1000\n",
            "36/36 - 4s - loss: 1.1018 - mae: 1.1018 - val_loss: 1.0507 - val_mae: 1.0507\n",
            "Epoch 702/1000\n",
            "36/36 - 4s - loss: 1.1047 - mae: 1.1047 - val_loss: 0.9228 - val_mae: 0.9228\n",
            "Epoch 703/1000\n",
            "36/36 - 4s - loss: 1.1232 - mae: 1.1232 - val_loss: 0.9272 - val_mae: 0.9272\n",
            "Epoch 704/1000\n",
            "36/36 - 4s - loss: 1.0827 - mae: 1.0827 - val_loss: 0.9990 - val_mae: 0.9990\n",
            "Epoch 705/1000\n",
            "36/36 - 4s - loss: 1.1466 - mae: 1.1466 - val_loss: 0.9623 - val_mae: 0.9623\n",
            "Epoch 706/1000\n",
            "36/36 - 4s - loss: 1.1788 - mae: 1.1788 - val_loss: 0.9841 - val_mae: 0.9841\n",
            "Epoch 707/1000\n",
            "36/36 - 4s - loss: 1.0925 - mae: 1.0925 - val_loss: 0.9717 - val_mae: 0.9717\n",
            "Epoch 708/1000\n",
            "36/36 - 4s - loss: 1.0905 - mae: 1.0905 - val_loss: 0.9566 - val_mae: 0.9566\n",
            "Epoch 709/1000\n",
            "36/36 - 4s - loss: 1.0188 - mae: 1.0188 - val_loss: 0.9005 - val_mae: 0.9005\n",
            "Epoch 710/1000\n",
            "36/36 - 4s - loss: 1.0634 - mae: 1.0634 - val_loss: 0.9299 - val_mae: 0.9299\n",
            "Epoch 711/1000\n",
            "36/36 - 4s - loss: 1.0340 - mae: 1.0340 - val_loss: 0.9832 - val_mae: 0.9832\n",
            "Epoch 712/1000\n",
            "36/36 - 4s - loss: 0.9807 - mae: 0.9807 - val_loss: 0.9783 - val_mae: 0.9783\n",
            "Epoch 713/1000\n",
            "36/36 - 4s - loss: 1.1175 - mae: 1.1175 - val_loss: 1.0871 - val_mae: 1.0871\n",
            "Epoch 714/1000\n",
            "36/36 - 4s - loss: 1.0601 - mae: 1.0601 - val_loss: 0.8719 - val_mae: 0.8719\n",
            "Epoch 715/1000\n",
            "36/36 - 4s - loss: 1.0972 - mae: 1.0972 - val_loss: 1.0835 - val_mae: 1.0835\n",
            "Epoch 716/1000\n",
            "36/36 - 4s - loss: 1.0875 - mae: 1.0875 - val_loss: 0.9786 - val_mae: 0.9786\n",
            "Epoch 717/1000\n",
            "36/36 - 4s - loss: 1.0252 - mae: 1.0252 - val_loss: 1.0519 - val_mae: 1.0519\n",
            "Epoch 718/1000\n",
            "36/36 - 4s - loss: 1.1381 - mae: 1.1381 - val_loss: 1.0257 - val_mae: 1.0257\n",
            "Epoch 719/1000\n",
            "36/36 - 4s - loss: 1.0042 - mae: 1.0042 - val_loss: 0.8980 - val_mae: 0.8980\n",
            "Epoch 720/1000\n",
            "36/36 - 4s - loss: 1.0188 - mae: 1.0188 - val_loss: 0.8782 - val_mae: 0.8782\n",
            "Epoch 721/1000\n",
            "36/36 - 4s - loss: 1.0384 - mae: 1.0384 - val_loss: 0.9946 - val_mae: 0.9946\n",
            "Epoch 722/1000\n",
            "36/36 - 4s - loss: 1.1654 - mae: 1.1654 - val_loss: 0.9951 - val_mae: 0.9951\n",
            "Epoch 723/1000\n",
            "36/36 - 4s - loss: 1.0425 - mae: 1.0425 - val_loss: 0.9184 - val_mae: 0.9184\n",
            "Epoch 724/1000\n",
            "36/36 - 4s - loss: 1.0849 - mae: 1.0849 - val_loss: 0.9036 - val_mae: 0.9036\n",
            "Epoch 725/1000\n",
            "36/36 - 4s - loss: 1.0048 - mae: 1.0048 - val_loss: 0.9483 - val_mae: 0.9483\n",
            "Epoch 726/1000\n",
            "36/36 - 4s - loss: 1.1069 - mae: 1.1069 - val_loss: 0.9400 - val_mae: 0.9400\n",
            "Epoch 727/1000\n",
            "36/36 - 4s - loss: 1.0775 - mae: 1.0775 - val_loss: 0.9479 - val_mae: 0.9479\n",
            "Epoch 728/1000\n",
            "36/36 - 4s - loss: 1.0587 - mae: 1.0587 - val_loss: 0.8294 - val_mae: 0.8294\n",
            "Epoch 729/1000\n",
            "36/36 - 4s - loss: 1.0337 - mae: 1.0337 - val_loss: 1.0301 - val_mae: 1.0301\n",
            "Epoch 730/1000\n",
            "36/36 - 4s - loss: 1.0338 - mae: 1.0338 - val_loss: 0.9145 - val_mae: 0.9145\n",
            "Epoch 731/1000\n",
            "36/36 - 4s - loss: 1.0188 - mae: 1.0188 - val_loss: 0.9094 - val_mae: 0.9094\n",
            "Epoch 732/1000\n",
            "36/36 - 4s - loss: 1.0933 - mae: 1.0933 - val_loss: 0.8161 - val_mae: 0.8161\n",
            "Epoch 733/1000\n",
            "36/36 - 4s - loss: 1.0422 - mae: 1.0422 - val_loss: 0.8244 - val_mae: 0.8244\n",
            "Epoch 734/1000\n",
            "36/36 - 4s - loss: 1.0335 - mae: 1.0335 - val_loss: 0.8318 - val_mae: 0.8318\n",
            "Epoch 735/1000\n",
            "36/36 - 4s - loss: 1.0537 - mae: 1.0537 - val_loss: 0.9725 - val_mae: 0.9725\n",
            "Epoch 736/1000\n",
            "36/36 - 4s - loss: 1.1121 - mae: 1.1121 - val_loss: 0.9260 - val_mae: 0.9260\n",
            "Epoch 737/1000\n",
            "36/36 - 4s - loss: 1.0450 - mae: 1.0450 - val_loss: 0.9116 - val_mae: 0.9116\n",
            "Epoch 738/1000\n",
            "36/36 - 4s - loss: 1.0104 - mae: 1.0104 - val_loss: 0.9614 - val_mae: 0.9614\n",
            "Epoch 739/1000\n",
            "36/36 - 4s - loss: 1.0071 - mae: 1.0071 - val_loss: 1.0244 - val_mae: 1.0244\n",
            "Epoch 740/1000\n",
            "36/36 - 4s - loss: 1.0877 - mae: 1.0877 - val_loss: 0.9637 - val_mae: 0.9637\n",
            "Epoch 741/1000\n",
            "36/36 - 4s - loss: 1.0485 - mae: 1.0485 - val_loss: 0.9110 - val_mae: 0.9110\n",
            "Epoch 742/1000\n",
            "36/36 - 4s - loss: 0.9854 - mae: 0.9854 - val_loss: 0.9022 - val_mae: 0.9022\n",
            "Epoch 743/1000\n",
            "36/36 - 4s - loss: 0.9751 - mae: 0.9751 - val_loss: 1.1058 - val_mae: 1.1058\n",
            "Epoch 744/1000\n",
            "36/36 - 4s - loss: 1.0249 - mae: 1.0249 - val_loss: 0.9102 - val_mae: 0.9102\n",
            "Epoch 745/1000\n",
            "36/36 - 4s - loss: 1.0854 - mae: 1.0854 - val_loss: 1.0090 - val_mae: 1.0090\n",
            "Epoch 746/1000\n",
            "36/36 - 4s - loss: 1.0282 - mae: 1.0282 - val_loss: 0.9393 - val_mae: 0.9393\n",
            "Epoch 747/1000\n",
            "36/36 - 4s - loss: 1.0769 - mae: 1.0769 - val_loss: 0.8428 - val_mae: 0.8428\n",
            "Epoch 748/1000\n",
            "36/36 - 4s - loss: 1.0007 - mae: 1.0007 - val_loss: 0.9101 - val_mae: 0.9101\n",
            "Epoch 749/1000\n",
            "36/36 - 4s - loss: 1.1022 - mae: 1.1022 - val_loss: 0.8763 - val_mae: 0.8763\n",
            "Epoch 750/1000\n",
            "36/36 - 4s - loss: 1.0253 - mae: 1.0253 - val_loss: 0.9656 - val_mae: 0.9656\n",
            "Epoch 751/1000\n",
            "36/36 - 4s - loss: 1.0483 - mae: 1.0483 - val_loss: 0.9735 - val_mae: 0.9735\n",
            "Epoch 752/1000\n",
            "36/36 - 4s - loss: 1.0013 - mae: 1.0013 - val_loss: 0.8529 - val_mae: 0.8529\n",
            "Epoch 753/1000\n",
            "36/36 - 4s - loss: 1.0077 - mae: 1.0077 - val_loss: 0.9443 - val_mae: 0.9443\n",
            "Epoch 754/1000\n",
            "36/36 - 4s - loss: 1.0425 - mae: 1.0425 - val_loss: 0.8983 - val_mae: 0.8983\n",
            "Epoch 755/1000\n",
            "36/36 - 4s - loss: 1.0833 - mae: 1.0833 - val_loss: 0.9558 - val_mae: 0.9558\n",
            "Epoch 756/1000\n",
            "36/36 - 4s - loss: 1.0084 - mae: 1.0084 - val_loss: 0.8635 - val_mae: 0.8635\n",
            "Epoch 757/1000\n",
            "36/36 - 4s - loss: 1.1025 - mae: 1.1025 - val_loss: 0.8568 - val_mae: 0.8568\n",
            "Epoch 758/1000\n",
            "36/36 - 4s - loss: 1.0102 - mae: 1.0102 - val_loss: 0.9043 - val_mae: 0.9043\n",
            "Epoch 759/1000\n",
            "36/36 - 4s - loss: 1.0713 - mae: 1.0713 - val_loss: 0.8684 - val_mae: 0.8684\n",
            "Epoch 760/1000\n",
            "36/36 - 4s - loss: 1.0931 - mae: 1.0931 - val_loss: 0.9921 - val_mae: 0.9921\n",
            "Epoch 761/1000\n",
            "36/36 - 4s - loss: 1.0086 - mae: 1.0086 - val_loss: 0.9030 - val_mae: 0.9030\n",
            "Epoch 762/1000\n",
            "36/36 - 4s - loss: 1.0794 - mae: 1.0794 - val_loss: 0.9015 - val_mae: 0.9015\n",
            "Epoch 763/1000\n",
            "36/36 - 4s - loss: 1.0477 - mae: 1.0477 - val_loss: 0.9543 - val_mae: 0.9543\n",
            "Epoch 764/1000\n",
            "36/36 - 4s - loss: 1.1539 - mae: 1.1539 - val_loss: 0.9242 - val_mae: 0.9242\n",
            "Epoch 765/1000\n",
            "36/36 - 4s - loss: 1.0095 - mae: 1.0095 - val_loss: 0.8700 - val_mae: 0.8700\n",
            "Epoch 766/1000\n",
            "36/36 - 4s - loss: 1.0326 - mae: 1.0326 - val_loss: 1.0432 - val_mae: 1.0432\n",
            "Epoch 767/1000\n",
            "36/36 - 4s - loss: 1.0860 - mae: 1.0860 - val_loss: 0.9963 - val_mae: 0.9963\n",
            "Epoch 768/1000\n",
            "36/36 - 4s - loss: 1.0168 - mae: 1.0168 - val_loss: 0.9869 - val_mae: 0.9869\n",
            "Epoch 769/1000\n",
            "36/36 - 4s - loss: 1.0134 - mae: 1.0134 - val_loss: 1.0624 - val_mae: 1.0624\n",
            "Epoch 770/1000\n",
            "36/36 - 4s - loss: 1.0204 - mae: 1.0204 - val_loss: 0.9759 - val_mae: 0.9759\n",
            "Epoch 771/1000\n",
            "36/36 - 4s - loss: 1.0451 - mae: 1.0451 - val_loss: 0.9228 - val_mae: 0.9228\n",
            "Epoch 772/1000\n",
            "36/36 - 4s - loss: 1.0277 - mae: 1.0277 - val_loss: 1.0030 - val_mae: 1.0030\n",
            "Epoch 773/1000\n",
            "36/36 - 4s - loss: 1.0442 - mae: 1.0442 - val_loss: 0.9294 - val_mae: 0.9294\n",
            "Epoch 774/1000\n",
            "36/36 - 4s - loss: 1.0339 - mae: 1.0339 - val_loss: 1.0002 - val_mae: 1.0002\n",
            "Epoch 775/1000\n",
            "36/36 - 4s - loss: 1.0739 - mae: 1.0739 - val_loss: 0.9060 - val_mae: 0.9060\n",
            "Epoch 776/1000\n",
            "36/36 - 4s - loss: 0.9603 - mae: 0.9603 - val_loss: 0.9906 - val_mae: 0.9906\n",
            "Epoch 777/1000\n",
            "36/36 - 4s - loss: 0.9968 - mae: 0.9968 - val_loss: 0.9047 - val_mae: 0.9047\n",
            "Epoch 778/1000\n",
            "36/36 - 4s - loss: 1.0125 - mae: 1.0125 - val_loss: 1.0099 - val_mae: 1.0099\n",
            "Epoch 779/1000\n",
            "36/36 - 4s - loss: 1.0796 - mae: 1.0796 - val_loss: 0.9703 - val_mae: 0.9703\n",
            "Epoch 780/1000\n",
            "36/36 - 4s - loss: 1.0134 - mae: 1.0134 - val_loss: 0.9677 - val_mae: 0.9677\n",
            "Epoch 781/1000\n",
            "36/36 - 4s - loss: 1.0376 - mae: 1.0376 - val_loss: 1.0275 - val_mae: 1.0275\n",
            "Epoch 782/1000\n",
            "36/36 - 4s - loss: 1.0823 - mae: 1.0823 - val_loss: 0.9436 - val_mae: 0.9436\n",
            "Epoch 783/1000\n",
            "36/36 - 4s - loss: 1.0172 - mae: 1.0172 - val_loss: 1.1639 - val_mae: 1.1639\n",
            "Epoch 784/1000\n",
            "36/36 - 4s - loss: 1.0188 - mae: 1.0188 - val_loss: 0.7912 - val_mae: 0.7912\n",
            "Epoch 785/1000\n",
            "36/36 - 4s - loss: 1.0114 - mae: 1.0114 - val_loss: 0.8651 - val_mae: 0.8651\n",
            "Epoch 786/1000\n",
            "36/36 - 4s - loss: 0.9612 - mae: 0.9612 - val_loss: 0.8263 - val_mae: 0.8263\n",
            "Epoch 787/1000\n",
            "36/36 - 4s - loss: 1.0592 - mae: 1.0592 - val_loss: 0.9188 - val_mae: 0.9188\n",
            "Epoch 788/1000\n",
            "36/36 - 4s - loss: 0.9927 - mae: 0.9927 - val_loss: 0.9646 - val_mae: 0.9646\n",
            "Epoch 789/1000\n",
            "36/36 - 4s - loss: 1.0472 - mae: 1.0472 - val_loss: 0.8661 - val_mae: 0.8661\n",
            "Epoch 790/1000\n",
            "36/36 - 4s - loss: 1.0550 - mae: 1.0550 - val_loss: 1.0423 - val_mae: 1.0423\n",
            "Epoch 791/1000\n",
            "36/36 - 4s - loss: 1.0385 - mae: 1.0385 - val_loss: 1.0711 - val_mae: 1.0711\n",
            "Epoch 792/1000\n",
            "36/36 - 4s - loss: 0.9963 - mae: 0.9963 - val_loss: 0.8596 - val_mae: 0.8596\n",
            "Epoch 793/1000\n",
            "36/36 - 4s - loss: 1.0172 - mae: 1.0172 - val_loss: 0.8448 - val_mae: 0.8448\n",
            "Epoch 794/1000\n",
            "36/36 - 4s - loss: 1.0014 - mae: 1.0014 - val_loss: 0.8880 - val_mae: 0.8880\n",
            "Epoch 795/1000\n",
            "36/36 - 4s - loss: 1.0228 - mae: 1.0228 - val_loss: 0.9243 - val_mae: 0.9243\n",
            "Epoch 796/1000\n",
            "36/36 - 4s - loss: 0.9901 - mae: 0.9901 - val_loss: 0.8934 - val_mae: 0.8934\n",
            "Epoch 797/1000\n",
            "36/36 - 4s - loss: 1.0442 - mae: 1.0442 - val_loss: 0.8653 - val_mae: 0.8653\n",
            "Epoch 798/1000\n",
            "36/36 - 4s - loss: 1.0219 - mae: 1.0219 - val_loss: 1.1048 - val_mae: 1.1048\n",
            "Epoch 799/1000\n",
            "36/36 - 4s - loss: 1.0874 - mae: 1.0874 - val_loss: 0.8471 - val_mae: 0.8471\n",
            "Epoch 800/1000\n",
            "36/36 - 4s - loss: 1.0267 - mae: 1.0267 - val_loss: 0.8648 - val_mae: 0.8648\n",
            "Epoch 801/1000\n",
            "36/36 - 4s - loss: 0.9869 - mae: 0.9869 - val_loss: 0.8884 - val_mae: 0.8884\n",
            "Epoch 802/1000\n",
            "36/36 - 4s - loss: 0.9804 - mae: 0.9804 - val_loss: 0.8667 - val_mae: 0.8667\n",
            "Epoch 803/1000\n",
            "36/36 - 4s - loss: 0.9942 - mae: 0.9942 - val_loss: 0.9675 - val_mae: 0.9675\n",
            "Epoch 804/1000\n",
            "36/36 - 4s - loss: 1.1222 - mae: 1.1222 - val_loss: 0.9583 - val_mae: 0.9583\n",
            "Epoch 805/1000\n",
            "36/36 - 4s - loss: 1.0634 - mae: 1.0634 - val_loss: 0.8531 - val_mae: 0.8531\n",
            "Epoch 806/1000\n",
            "36/36 - 4s - loss: 1.0596 - mae: 1.0596 - val_loss: 0.8992 - val_mae: 0.8992\n",
            "Epoch 807/1000\n",
            "36/36 - 4s - loss: 0.9671 - mae: 0.9671 - val_loss: 1.0619 - val_mae: 1.0619\n",
            "Epoch 808/1000\n",
            "36/36 - 4s - loss: 1.0283 - mae: 1.0283 - val_loss: 0.9149 - val_mae: 0.9149\n",
            "Epoch 809/1000\n",
            "36/36 - 4s - loss: 0.9833 - mae: 0.9833 - val_loss: 0.8948 - val_mae: 0.8948\n",
            "Epoch 810/1000\n",
            "36/36 - 4s - loss: 0.9689 - mae: 0.9689 - val_loss: 0.8457 - val_mae: 0.8457\n",
            "Epoch 811/1000\n",
            "36/36 - 4s - loss: 1.0343 - mae: 1.0343 - val_loss: 0.9207 - val_mae: 0.9207\n",
            "Epoch 812/1000\n",
            "36/36 - 4s - loss: 1.0650 - mae: 1.0650 - val_loss: 0.8855 - val_mae: 0.8855\n",
            "Epoch 813/1000\n",
            "36/36 - 4s - loss: 1.0317 - mae: 1.0317 - val_loss: 0.8501 - val_mae: 0.8501\n",
            "Epoch 814/1000\n",
            "36/36 - 4s - loss: 0.9394 - mae: 0.9394 - val_loss: 0.8150 - val_mae: 0.8150\n",
            "Epoch 815/1000\n",
            "36/36 - 4s - loss: 0.9561 - mae: 0.9561 - val_loss: 0.8925 - val_mae: 0.8925\n",
            "Epoch 816/1000\n",
            "36/36 - 4s - loss: 1.0121 - mae: 1.0121 - val_loss: 0.9541 - val_mae: 0.9541\n",
            "Epoch 817/1000\n",
            "36/36 - 4s - loss: 1.0504 - mae: 1.0504 - val_loss: 0.8825 - val_mae: 0.8825\n",
            "Epoch 818/1000\n",
            "36/36 - 4s - loss: 0.9991 - mae: 0.9991 - val_loss: 0.8604 - val_mae: 0.8604\n",
            "Epoch 819/1000\n",
            "36/36 - 4s - loss: 1.0114 - mae: 1.0114 - val_loss: 0.8126 - val_mae: 0.8126\n",
            "Epoch 820/1000\n",
            "36/36 - 4s - loss: 1.0723 - mae: 1.0723 - val_loss: 0.9518 - val_mae: 0.9518\n",
            "Epoch 821/1000\n",
            "36/36 - 4s - loss: 1.0683 - mae: 1.0683 - val_loss: 1.1098 - val_mae: 1.1098\n",
            "Epoch 822/1000\n",
            "36/36 - 4s - loss: 1.0105 - mae: 1.0105 - val_loss: 0.8523 - val_mae: 0.8523\n",
            "Epoch 823/1000\n",
            "36/36 - 4s - loss: 0.9577 - mae: 0.9577 - val_loss: 0.9094 - val_mae: 0.9094\n",
            "Epoch 824/1000\n",
            "36/36 - 4s - loss: 1.0170 - mae: 1.0170 - val_loss: 0.9011 - val_mae: 0.9011\n",
            "Epoch 825/1000\n",
            "36/36 - 4s - loss: 0.9870 - mae: 0.9870 - val_loss: 0.8342 - val_mae: 0.8342\n",
            "Epoch 826/1000\n",
            "36/36 - 4s - loss: 1.0001 - mae: 1.0001 - val_loss: 0.9662 - val_mae: 0.9662\n",
            "Epoch 827/1000\n",
            "36/36 - 4s - loss: 1.1300 - mae: 1.1300 - val_loss: 0.8546 - val_mae: 0.8546\n",
            "Epoch 828/1000\n",
            "36/36 - 4s - loss: 0.9672 - mae: 0.9672 - val_loss: 0.9432 - val_mae: 0.9432\n",
            "Epoch 829/1000\n",
            "36/36 - 4s - loss: 1.0229 - mae: 1.0229 - val_loss: 0.9729 - val_mae: 0.9729\n",
            "Epoch 830/1000\n",
            "36/36 - 4s - loss: 0.9703 - mae: 0.9703 - val_loss: 0.9154 - val_mae: 0.9154\n",
            "Epoch 831/1000\n",
            "36/36 - 4s - loss: 0.9866 - mae: 0.9866 - val_loss: 0.8609 - val_mae: 0.8609\n",
            "Epoch 832/1000\n",
            "36/36 - 4s - loss: 1.0453 - mae: 1.0453 - val_loss: 0.9568 - val_mae: 0.9568\n",
            "Epoch 833/1000\n",
            "36/36 - 4s - loss: 0.9559 - mae: 0.9559 - val_loss: 0.8246 - val_mae: 0.8246\n",
            "Epoch 834/1000\n",
            "36/36 - 4s - loss: 0.9998 - mae: 0.9998 - val_loss: 0.9105 - val_mae: 0.9105\n",
            "Epoch 835/1000\n",
            "36/36 - 4s - loss: 0.9277 - mae: 0.9277 - val_loss: 0.9684 - val_mae: 0.9684\n",
            "Epoch 836/1000\n",
            "36/36 - 4s - loss: 0.9585 - mae: 0.9585 - val_loss: 0.8499 - val_mae: 0.8499\n",
            "Epoch 837/1000\n",
            "36/36 - 4s - loss: 0.9402 - mae: 0.9402 - val_loss: 0.9539 - val_mae: 0.9539\n",
            "Epoch 838/1000\n",
            "36/36 - 4s - loss: 1.0389 - mae: 1.0389 - val_loss: 0.8383 - val_mae: 0.8383\n",
            "Epoch 839/1000\n",
            "36/36 - 4s - loss: 1.0218 - mae: 1.0218 - val_loss: 0.8959 - val_mae: 0.8959\n",
            "Epoch 840/1000\n",
            "36/36 - 4s - loss: 1.0084 - mae: 1.0084 - val_loss: 0.8658 - val_mae: 0.8658\n",
            "Epoch 841/1000\n",
            "36/36 - 4s - loss: 1.0098 - mae: 1.0098 - val_loss: 0.9346 - val_mae: 0.9346\n",
            "Epoch 842/1000\n",
            "36/36 - 4s - loss: 0.9215 - mae: 0.9215 - val_loss: 0.8360 - val_mae: 0.8360\n",
            "Epoch 843/1000\n",
            "36/36 - 4s - loss: 0.9807 - mae: 0.9807 - val_loss: 1.0110 - val_mae: 1.0110\n",
            "Epoch 844/1000\n",
            "36/36 - 4s - loss: 0.9793 - mae: 0.9793 - val_loss: 0.7952 - val_mae: 0.7952\n",
            "Epoch 845/1000\n",
            "36/36 - 4s - loss: 0.9304 - mae: 0.9304 - val_loss: 0.9090 - val_mae: 0.9090\n",
            "Epoch 846/1000\n",
            "36/36 - 4s - loss: 1.0059 - mae: 1.0059 - val_loss: 0.8662 - val_mae: 0.8662\n",
            "Epoch 847/1000\n",
            "36/36 - 4s - loss: 1.0116 - mae: 1.0116 - val_loss: 0.9090 - val_mae: 0.9090\n",
            "Epoch 848/1000\n",
            "36/36 - 4s - loss: 0.9349 - mae: 0.9349 - val_loss: 0.7871 - val_mae: 0.7871\n",
            "Epoch 849/1000\n",
            "36/36 - 4s - loss: 0.9361 - mae: 0.9361 - val_loss: 0.9328 - val_mae: 0.9328\n",
            "Epoch 850/1000\n",
            "36/36 - 4s - loss: 1.0183 - mae: 1.0183 - val_loss: 0.9425 - val_mae: 0.9425\n",
            "Epoch 851/1000\n",
            "36/36 - 4s - loss: 0.9804 - mae: 0.9804 - val_loss: 0.8694 - val_mae: 0.8694\n",
            "Epoch 852/1000\n",
            "36/36 - 4s - loss: 0.9994 - mae: 0.9994 - val_loss: 0.8517 - val_mae: 0.8517\n",
            "Epoch 853/1000\n",
            "36/36 - 4s - loss: 1.0121 - mae: 1.0121 - val_loss: 0.8209 - val_mae: 0.8209\n",
            "Epoch 854/1000\n",
            "36/36 - 4s - loss: 0.9640 - mae: 0.9640 - val_loss: 0.9204 - val_mae: 0.9204\n",
            "Epoch 855/1000\n",
            "36/36 - 4s - loss: 0.9445 - mae: 0.9445 - val_loss: 0.8304 - val_mae: 0.8304\n",
            "Epoch 856/1000\n",
            "36/36 - 4s - loss: 1.0075 - mae: 1.0075 - val_loss: 0.8281 - val_mae: 0.8281\n",
            "Epoch 857/1000\n",
            "36/36 - 4s - loss: 0.9521 - mae: 0.9521 - val_loss: 0.9349 - val_mae: 0.9349\n",
            "Epoch 858/1000\n",
            "36/36 - 4s - loss: 0.9605 - mae: 0.9605 - val_loss: 0.9197 - val_mae: 0.9197\n",
            "Epoch 859/1000\n",
            "36/36 - 4s - loss: 0.9535 - mae: 0.9535 - val_loss: 0.8780 - val_mae: 0.8780\n",
            "Epoch 860/1000\n",
            "36/36 - 4s - loss: 0.8689 - mae: 0.8689 - val_loss: 0.8720 - val_mae: 0.8720\n",
            "Epoch 861/1000\n",
            "36/36 - 4s - loss: 1.0354 - mae: 1.0354 - val_loss: 0.8468 - val_mae: 0.8468\n",
            "Epoch 862/1000\n",
            "36/36 - 4s - loss: 0.9221 - mae: 0.9221 - val_loss: 0.7888 - val_mae: 0.7888\n",
            "Epoch 863/1000\n",
            "36/36 - 4s - loss: 1.0021 - mae: 1.0021 - val_loss: 0.9222 - val_mae: 0.9222\n",
            "Epoch 864/1000\n",
            "36/36 - 4s - loss: 0.9583 - mae: 0.9583 - val_loss: 0.8772 - val_mae: 0.8772\n",
            "Epoch 865/1000\n",
            "36/36 - 4s - loss: 1.0329 - mae: 1.0329 - val_loss: 0.8227 - val_mae: 0.8227\n",
            "Epoch 866/1000\n",
            "36/36 - 4s - loss: 0.9153 - mae: 0.9153 - val_loss: 0.8156 - val_mae: 0.8156\n",
            "Epoch 867/1000\n",
            "36/36 - 4s - loss: 0.9713 - mae: 0.9713 - val_loss: 0.8925 - val_mae: 0.8925\n",
            "Epoch 868/1000\n",
            "36/36 - 4s - loss: 1.0357 - mae: 1.0357 - val_loss: 0.8256 - val_mae: 0.8256\n",
            "Epoch 869/1000\n",
            "36/36 - 4s - loss: 1.0272 - mae: 1.0272 - val_loss: 0.9169 - val_mae: 0.9169\n",
            "Epoch 870/1000\n",
            "36/36 - 4s - loss: 0.9678 - mae: 0.9678 - val_loss: 0.7349 - val_mae: 0.7349\n",
            "Epoch 871/1000\n",
            "36/36 - 4s - loss: 0.9618 - mae: 0.9618 - val_loss: 0.9920 - val_mae: 0.9920\n",
            "Epoch 872/1000\n",
            "36/36 - 4s - loss: 0.9763 - mae: 0.9763 - val_loss: 0.9533 - val_mae: 0.9533\n",
            "Epoch 873/1000\n",
            "36/36 - 4s - loss: 0.9402 - mae: 0.9402 - val_loss: 0.9403 - val_mae: 0.9403\n",
            "Epoch 874/1000\n",
            "36/36 - 4s - loss: 0.9698 - mae: 0.9698 - val_loss: 0.8596 - val_mae: 0.8596\n",
            "Epoch 875/1000\n",
            "36/36 - 4s - loss: 0.9257 - mae: 0.9257 - val_loss: 0.8264 - val_mae: 0.8264\n",
            "Epoch 876/1000\n",
            "36/36 - 4s - loss: 0.9757 - mae: 0.9757 - val_loss: 0.8514 - val_mae: 0.8514\n",
            "Epoch 877/1000\n",
            "36/36 - 4s - loss: 0.9143 - mae: 0.9143 - val_loss: 0.8504 - val_mae: 0.8504\n",
            "Epoch 878/1000\n",
            "36/36 - 4s - loss: 0.8750 - mae: 0.8750 - val_loss: 0.8193 - val_mae: 0.8193\n",
            "Epoch 879/1000\n",
            "36/36 - 4s - loss: 1.0320 - mae: 1.0320 - val_loss: 0.8863 - val_mae: 0.8863\n",
            "Epoch 880/1000\n",
            "36/36 - 4s - loss: 1.0356 - mae: 1.0356 - val_loss: 0.8622 - val_mae: 0.8622\n",
            "Epoch 881/1000\n",
            "36/36 - 4s - loss: 0.8954 - mae: 0.8954 - val_loss: 0.8514 - val_mae: 0.8514\n",
            "Epoch 882/1000\n",
            "36/36 - 4s - loss: 0.9757 - mae: 0.9757 - val_loss: 0.8324 - val_mae: 0.8324\n",
            "Epoch 883/1000\n",
            "36/36 - 4s - loss: 0.9614 - mae: 0.9614 - val_loss: 0.8104 - val_mae: 0.8104\n",
            "Epoch 884/1000\n",
            "36/36 - 4s - loss: 0.9149 - mae: 0.9149 - val_loss: 0.8412 - val_mae: 0.8412\n",
            "Epoch 885/1000\n",
            "36/36 - 4s - loss: 0.9767 - mae: 0.9767 - val_loss: 0.8881 - val_mae: 0.8881\n",
            "Epoch 886/1000\n",
            "36/36 - 4s - loss: 0.9343 - mae: 0.9343 - val_loss: 0.8053 - val_mae: 0.8053\n",
            "Epoch 887/1000\n",
            "36/36 - 4s - loss: 0.9843 - mae: 0.9843 - val_loss: 0.8760 - val_mae: 0.8760\n",
            "Epoch 888/1000\n",
            "36/36 - 4s - loss: 0.9534 - mae: 0.9534 - val_loss: 0.8166 - val_mae: 0.8166\n",
            "Epoch 889/1000\n",
            "36/36 - 4s - loss: 0.9310 - mae: 0.9310 - val_loss: 0.7886 - val_mae: 0.7886\n",
            "Epoch 890/1000\n",
            "36/36 - 4s - loss: 0.9625 - mae: 0.9625 - val_loss: 0.9198 - val_mae: 0.9198\n",
            "Epoch 891/1000\n",
            "36/36 - 4s - loss: 1.0122 - mae: 1.0122 - val_loss: 1.0016 - val_mae: 1.0016\n",
            "Epoch 892/1000\n",
            "36/36 - 4s - loss: 0.9400 - mae: 0.9400 - val_loss: 0.8559 - val_mae: 0.8559\n",
            "Epoch 893/1000\n",
            "36/36 - 4s - loss: 0.9736 - mae: 0.9736 - val_loss: 0.8461 - val_mae: 0.8461\n",
            "Epoch 894/1000\n",
            "36/36 - 4s - loss: 0.9637 - mae: 0.9637 - val_loss: 0.9000 - val_mae: 0.9000\n",
            "Epoch 895/1000\n",
            "36/36 - 4s - loss: 0.9883 - mae: 0.9883 - val_loss: 0.8765 - val_mae: 0.8765\n",
            "Epoch 896/1000\n",
            "36/36 - 4s - loss: 0.9412 - mae: 0.9412 - val_loss: 0.8116 - val_mae: 0.8116\n",
            "Epoch 897/1000\n",
            "36/36 - 4s - loss: 0.9082 - mae: 0.9082 - val_loss: 0.8004 - val_mae: 0.8004\n",
            "Epoch 898/1000\n",
            "36/36 - 4s - loss: 1.0159 - mae: 1.0159 - val_loss: 0.8641 - val_mae: 0.8641\n",
            "Epoch 899/1000\n",
            "36/36 - 4s - loss: 0.9573 - mae: 0.9573 - val_loss: 0.8475 - val_mae: 0.8475\n",
            "Epoch 900/1000\n",
            "36/36 - 4s - loss: 0.9630 - mae: 0.9630 - val_loss: 0.7820 - val_mae: 0.7820\n",
            "Epoch 901/1000\n",
            "36/36 - 4s - loss: 0.9437 - mae: 0.9437 - val_loss: 0.8276 - val_mae: 0.8276\n",
            "Epoch 902/1000\n",
            "36/36 - 4s - loss: 0.9357 - mae: 0.9357 - val_loss: 0.8183 - val_mae: 0.8183\n",
            "Epoch 903/1000\n",
            "36/36 - 4s - loss: 0.9351 - mae: 0.9351 - val_loss: 0.8043 - val_mae: 0.8043\n",
            "Epoch 904/1000\n",
            "36/36 - 4s - loss: 0.8949 - mae: 0.8949 - val_loss: 0.7820 - val_mae: 0.7820\n",
            "Epoch 905/1000\n",
            "36/36 - 4s - loss: 0.9869 - mae: 0.9869 - val_loss: 0.8618 - val_mae: 0.8618\n",
            "Epoch 906/1000\n",
            "36/36 - 4s - loss: 0.8932 - mae: 0.8932 - val_loss: 0.7546 - val_mae: 0.7546\n",
            "Epoch 907/1000\n",
            "36/36 - 4s - loss: 0.9564 - mae: 0.9564 - val_loss: 0.9589 - val_mae: 0.9589\n",
            "Epoch 908/1000\n",
            "36/36 - 4s - loss: 0.9787 - mae: 0.9787 - val_loss: 0.8941 - val_mae: 0.8941\n",
            "Epoch 909/1000\n",
            "36/36 - 4s - loss: 0.9068 - mae: 0.9068 - val_loss: 0.9777 - val_mae: 0.9777\n",
            "Epoch 910/1000\n",
            "36/36 - 4s - loss: 0.9303 - mae: 0.9303 - val_loss: 0.9628 - val_mae: 0.9628\n",
            "Epoch 911/1000\n",
            "36/36 - 4s - loss: 0.9768 - mae: 0.9768 - val_loss: 0.8316 - val_mae: 0.8316\n",
            "Epoch 912/1000\n",
            "36/36 - 4s - loss: 0.9634 - mae: 0.9634 - val_loss: 0.9577 - val_mae: 0.9577\n",
            "Epoch 913/1000\n",
            "36/36 - 4s - loss: 0.9661 - mae: 0.9661 - val_loss: 0.7543 - val_mae: 0.7543\n",
            "Epoch 914/1000\n",
            "36/36 - 4s - loss: 0.9185 - mae: 0.9185 - val_loss: 0.8000 - val_mae: 0.8000\n",
            "Epoch 915/1000\n",
            "36/36 - 4s - loss: 0.9223 - mae: 0.9223 - val_loss: 0.8079 - val_mae: 0.8079\n",
            "Epoch 916/1000\n",
            "36/36 - 4s - loss: 0.9226 - mae: 0.9226 - val_loss: 0.8532 - val_mae: 0.8532\n",
            "Epoch 917/1000\n",
            "36/36 - 4s - loss: 1.0009 - mae: 1.0009 - val_loss: 0.9566 - val_mae: 0.9566\n",
            "Epoch 918/1000\n",
            "36/36 - 4s - loss: 0.9357 - mae: 0.9357 - val_loss: 0.8072 - val_mae: 0.8072\n",
            "Epoch 919/1000\n",
            "36/36 - 4s - loss: 0.8658 - mae: 0.8658 - val_loss: 0.8300 - val_mae: 0.8300\n",
            "Epoch 920/1000\n",
            "36/36 - 4s - loss: 0.9723 - mae: 0.9723 - val_loss: 0.9379 - val_mae: 0.9379\n",
            "Epoch 921/1000\n",
            "36/36 - 4s - loss: 0.9028 - mae: 0.9028 - val_loss: 0.7712 - val_mae: 0.7712\n",
            "Epoch 922/1000\n",
            "36/36 - 4s - loss: 0.9797 - mae: 0.9797 - val_loss: 0.8286 - val_mae: 0.8286\n",
            "Epoch 923/1000\n",
            "36/36 - 4s - loss: 0.9313 - mae: 0.9313 - val_loss: 0.8725 - val_mae: 0.8725\n",
            "Epoch 924/1000\n",
            "36/36 - 4s - loss: 0.9589 - mae: 0.9589 - val_loss: 0.9406 - val_mae: 0.9406\n",
            "Epoch 925/1000\n",
            "36/36 - 4s - loss: 0.9971 - mae: 0.9971 - val_loss: 0.9810 - val_mae: 0.9810\n",
            "Epoch 926/1000\n",
            "36/36 - 4s - loss: 0.9519 - mae: 0.9519 - val_loss: 0.8097 - val_mae: 0.8097\n",
            "Epoch 927/1000\n",
            "36/36 - 4s - loss: 0.9188 - mae: 0.9188 - val_loss: 0.7728 - val_mae: 0.7728\n",
            "Epoch 928/1000\n",
            "36/36 - 4s - loss: 0.9670 - mae: 0.9670 - val_loss: 1.1643 - val_mae: 1.1643\n",
            "Epoch 929/1000\n",
            "36/36 - 4s - loss: 0.9582 - mae: 0.9582 - val_loss: 0.9067 - val_mae: 0.9067\n",
            "Epoch 930/1000\n",
            "36/36 - 4s - loss: 0.9677 - mae: 0.9677 - val_loss: 0.8315 - val_mae: 0.8315\n",
            "Epoch 931/1000\n",
            "36/36 - 4s - loss: 0.9153 - mae: 0.9153 - val_loss: 0.8337 - val_mae: 0.8337\n",
            "Epoch 932/1000\n",
            "36/36 - 4s - loss: 0.9052 - mae: 0.9052 - val_loss: 0.8086 - val_mae: 0.8086\n",
            "Epoch 933/1000\n",
            "36/36 - 4s - loss: 0.8962 - mae: 0.8962 - val_loss: 0.8416 - val_mae: 0.8416\n",
            "Epoch 934/1000\n",
            "36/36 - 4s - loss: 0.9371 - mae: 0.9371 - val_loss: 0.8987 - val_mae: 0.8987\n",
            "Epoch 935/1000\n",
            "36/36 - 4s - loss: 0.9437 - mae: 0.9437 - val_loss: 0.7703 - val_mae: 0.7703\n",
            "Epoch 936/1000\n",
            "36/36 - 4s - loss: 0.9281 - mae: 0.9281 - val_loss: 0.9015 - val_mae: 0.9015\n",
            "Epoch 937/1000\n",
            "36/36 - 4s - loss: 0.9520 - mae: 0.9520 - val_loss: 0.8292 - val_mae: 0.8292\n",
            "Epoch 938/1000\n",
            "36/36 - 4s - loss: 0.9473 - mae: 0.9473 - val_loss: 0.8573 - val_mae: 0.8573\n",
            "Epoch 939/1000\n",
            "36/36 - 4s - loss: 0.8909 - mae: 0.8909 - val_loss: 0.9160 - val_mae: 0.9160\n",
            "Epoch 940/1000\n",
            "36/36 - 4s - loss: 0.9360 - mae: 0.9360 - val_loss: 0.8672 - val_mae: 0.8672\n",
            "Epoch 941/1000\n",
            "36/36 - 4s - loss: 0.8926 - mae: 0.8926 - val_loss: 0.8984 - val_mae: 0.8984\n",
            "Epoch 942/1000\n",
            "36/36 - 4s - loss: 0.9218 - mae: 0.9218 - val_loss: 0.7919 - val_mae: 0.7919\n",
            "Epoch 943/1000\n",
            "36/36 - 4s - loss: 0.9423 - mae: 0.9423 - val_loss: 0.9679 - val_mae: 0.9679\n",
            "Epoch 944/1000\n",
            "36/36 - 4s - loss: 0.9437 - mae: 0.9437 - val_loss: 0.8295 - val_mae: 0.8295\n",
            "Epoch 945/1000\n",
            "36/36 - 4s - loss: 0.9989 - mae: 0.9989 - val_loss: 0.8852 - val_mae: 0.8852\n",
            "Epoch 946/1000\n",
            "36/36 - 4s - loss: 0.9338 - mae: 0.9338 - val_loss: 0.7995 - val_mae: 0.7995\n",
            "Epoch 947/1000\n",
            "36/36 - 4s - loss: 0.9044 - mae: 0.9044 - val_loss: 0.8166 - val_mae: 0.8166\n",
            "Epoch 948/1000\n",
            "36/36 - 4s - loss: 0.9088 - mae: 0.9088 - val_loss: 0.8075 - val_mae: 0.8075\n",
            "Epoch 949/1000\n",
            "36/36 - 4s - loss: 0.8781 - mae: 0.8781 - val_loss: 0.9625 - val_mae: 0.9625\n",
            "Epoch 950/1000\n",
            "36/36 - 4s - loss: 0.8836 - mae: 0.8836 - val_loss: 0.7815 - val_mae: 0.7815\n",
            "Epoch 951/1000\n",
            "36/36 - 4s - loss: 0.9436 - mae: 0.9436 - val_loss: 0.9153 - val_mae: 0.9153\n",
            "Epoch 952/1000\n",
            "36/36 - 4s - loss: 0.9673 - mae: 0.9673 - val_loss: 0.8368 - val_mae: 0.8368\n",
            "Epoch 953/1000\n",
            "36/36 - 4s - loss: 0.9030 - mae: 0.9030 - val_loss: 0.8622 - val_mae: 0.8622\n",
            "Epoch 954/1000\n",
            "36/36 - 4s - loss: 0.9294 - mae: 0.9294 - val_loss: 0.8133 - val_mae: 0.8133\n",
            "Epoch 955/1000\n",
            "36/36 - 4s - loss: 0.8697 - mae: 0.8697 - val_loss: 0.8307 - val_mae: 0.8307\n",
            "Epoch 956/1000\n",
            "36/36 - 4s - loss: 0.9361 - mae: 0.9361 - val_loss: 0.8018 - val_mae: 0.8018\n",
            "Epoch 957/1000\n",
            "36/36 - 4s - loss: 0.8963 - mae: 0.8963 - val_loss: 0.7821 - val_mae: 0.7821\n",
            "Epoch 958/1000\n",
            "36/36 - 4s - loss: 0.9375 - mae: 0.9375 - val_loss: 0.9260 - val_mae: 0.9260\n",
            "Epoch 959/1000\n",
            "36/36 - 4s - loss: 0.9525 - mae: 0.9525 - val_loss: 0.8818 - val_mae: 0.8818\n",
            "Epoch 960/1000\n",
            "36/36 - 4s - loss: 0.9636 - mae: 0.9636 - val_loss: 0.8784 - val_mae: 0.8784\n",
            "Epoch 961/1000\n",
            "36/36 - 4s - loss: 0.8929 - mae: 0.8929 - val_loss: 0.7592 - val_mae: 0.7592\n",
            "Epoch 962/1000\n",
            "36/36 - 4s - loss: 0.9468 - mae: 0.9468 - val_loss: 0.8624 - val_mae: 0.8624\n",
            "Epoch 963/1000\n",
            "36/36 - 4s - loss: 0.9019 - mae: 0.9019 - val_loss: 0.8140 - val_mae: 0.8140\n",
            "Epoch 964/1000\n",
            "36/36 - 4s - loss: 0.9102 - mae: 0.9102 - val_loss: 0.8609 - val_mae: 0.8609\n",
            "Epoch 965/1000\n",
            "36/36 - 4s - loss: 0.9511 - mae: 0.9511 - val_loss: 0.8013 - val_mae: 0.8013\n",
            "Epoch 966/1000\n",
            "36/36 - 4s - loss: 0.9689 - mae: 0.9689 - val_loss: 0.7729 - val_mae: 0.7729\n",
            "Epoch 967/1000\n",
            "36/36 - 4s - loss: 0.9080 - mae: 0.9080 - val_loss: 0.7550 - val_mae: 0.7550\n",
            "Epoch 968/1000\n",
            "36/36 - 4s - loss: 0.9461 - mae: 0.9461 - val_loss: 0.8067 - val_mae: 0.8067\n",
            "Epoch 969/1000\n",
            "36/36 - 4s - loss: 0.9024 - mae: 0.9024 - val_loss: 0.8005 - val_mae: 0.8005\n",
            "Epoch 970/1000\n",
            "36/36 - 4s - loss: 0.9573 - mae: 0.9573 - val_loss: 0.8509 - val_mae: 0.8509\n",
            "Epoch 971/1000\n",
            "36/36 - 4s - loss: 0.9376 - mae: 0.9376 - val_loss: 0.9129 - val_mae: 0.9129\n",
            "Epoch 972/1000\n",
            "36/36 - 4s - loss: 0.8741 - mae: 0.8741 - val_loss: 0.8047 - val_mae: 0.8047\n",
            "Epoch 973/1000\n",
            "36/36 - 4s - loss: 0.8860 - mae: 0.8860 - val_loss: 0.7645 - val_mae: 0.7645\n",
            "Epoch 974/1000\n",
            "36/36 - 4s - loss: 0.8622 - mae: 0.8622 - val_loss: 0.7809 - val_mae: 0.7809\n",
            "Epoch 975/1000\n",
            "36/36 - 4s - loss: 0.8931 - mae: 0.8931 - val_loss: 0.7662 - val_mae: 0.7662\n",
            "Epoch 976/1000\n",
            "36/36 - 4s - loss: 0.9029 - mae: 0.9029 - val_loss: 0.7850 - val_mae: 0.7850\n",
            "Epoch 977/1000\n",
            "36/36 - 4s - loss: 0.8894 - mae: 0.8894 - val_loss: 0.9279 - val_mae: 0.9279\n",
            "Epoch 978/1000\n",
            "36/36 - 4s - loss: 0.8466 - mae: 0.8466 - val_loss: 0.8295 - val_mae: 0.8295\n",
            "Epoch 979/1000\n",
            "36/36 - 4s - loss: 0.9288 - mae: 0.9288 - val_loss: 0.8780 - val_mae: 0.8780\n",
            "Epoch 980/1000\n",
            "36/36 - 4s - loss: 0.9428 - mae: 0.9428 - val_loss: 0.8653 - val_mae: 0.8653\n",
            "Epoch 981/1000\n",
            "36/36 - 4s - loss: 0.9412 - mae: 0.9412 - val_loss: 0.9044 - val_mae: 0.9044\n",
            "Epoch 982/1000\n",
            "36/36 - 4s - loss: 0.9145 - mae: 0.9145 - val_loss: 0.8881 - val_mae: 0.8881\n",
            "Epoch 983/1000\n",
            "36/36 - 4s - loss: 0.9494 - mae: 0.9494 - val_loss: 0.8786 - val_mae: 0.8786\n",
            "Epoch 984/1000\n",
            "36/36 - 4s - loss: 0.8889 - mae: 0.8889 - val_loss: 0.8152 - val_mae: 0.8152\n",
            "Epoch 985/1000\n",
            "36/36 - 4s - loss: 0.8677 - mae: 0.8677 - val_loss: 0.8132 - val_mae: 0.8132\n",
            "Epoch 986/1000\n",
            "36/36 - 4s - loss: 0.8900 - mae: 0.8900 - val_loss: 0.8539 - val_mae: 0.8539\n",
            "Epoch 987/1000\n",
            "36/36 - 4s - loss: 1.0068 - mae: 1.0068 - val_loss: 0.8822 - val_mae: 0.8822\n",
            "Epoch 988/1000\n",
            "36/36 - 4s - loss: 0.9198 - mae: 0.9198 - val_loss: 0.7904 - val_mae: 0.7904\n",
            "Epoch 989/1000\n",
            "36/36 - 4s - loss: 0.8734 - mae: 0.8734 - val_loss: 0.8061 - val_mae: 0.8061\n",
            "Epoch 990/1000\n",
            "36/36 - 4s - loss: 0.8889 - mae: 0.8889 - val_loss: 0.8637 - val_mae: 0.8637\n",
            "Epoch 991/1000\n",
            "36/36 - 4s - loss: 0.9664 - mae: 0.9664 - val_loss: 0.8854 - val_mae: 0.8854\n",
            "Epoch 992/1000\n",
            "36/36 - 4s - loss: 0.8883 - mae: 0.8883 - val_loss: 0.8544 - val_mae: 0.8544\n",
            "Epoch 993/1000\n",
            "36/36 - 4s - loss: 0.9790 - mae: 0.9790 - val_loss: 0.7670 - val_mae: 0.7670\n",
            "Epoch 994/1000\n",
            "36/36 - 4s - loss: 0.9361 - mae: 0.9361 - val_loss: 0.9193 - val_mae: 0.9193\n",
            "Epoch 995/1000\n",
            "36/36 - 4s - loss: 0.9167 - mae: 0.9167 - val_loss: 0.8214 - val_mae: 0.8214\n",
            "Epoch 996/1000\n",
            "36/36 - 4s - loss: 0.8713 - mae: 0.8713 - val_loss: 0.7915 - val_mae: 0.7915\n",
            "Epoch 997/1000\n",
            "36/36 - 4s - loss: 0.9773 - mae: 0.9773 - val_loss: 0.9027 - val_mae: 0.9027\n",
            "Epoch 998/1000\n",
            "36/36 - 4s - loss: 0.8463 - mae: 0.8463 - val_loss: 0.7635 - val_mae: 0.7635\n",
            "Epoch 999/1000\n",
            "36/36 - 4s - loss: 0.9418 - mae: 0.9418 - val_loss: 0.7922 - val_mae: 0.7922\n",
            "Epoch 1000/1000\n",
            "36/36 - 4s - loss: 0.8992 - mae: 0.8992 - val_loss: 0.8769 - val_mae: 0.8769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0818c6d208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUo3AxhLqO81",
        "colab_type": "code",
        "outputId": "f755204f-8bc0-47c3-baba-681c3f1762b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model.evaluate(x_eval, y_eval)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "532/532 [==============================] - 1s 3ms/step - loss: 0.8609 - mae: 0.8609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8609458804130554, 0.8609458804130554]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJYUw-Q3qPqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(x_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8TskHM9qZOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_test = model.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orzGNwdKqg0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
